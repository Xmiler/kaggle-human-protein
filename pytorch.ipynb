{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from utils import ProteinDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(root_dir):\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = ProteinDataset(root_dir / 'train.csv', root_dir / 'train', colors=['red', 'green', 'blue'],\n",
    "                             transforms=data_transform)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=16, num_workers=4, shuffle=True)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "def create_model(arch, device_id):\n",
    "    \n",
    "    class Flatten(nn.Module):\n",
    "        \"Flatten `x` to a single dimension, often used at the end of a model.\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return x.view((x.size(0), -1)) \n",
    "    \n",
    "    body = nn.Sequential(*list(arch.children())[:-1])\n",
    "    head = nn.Sequential(Flatten(), nn.Linear(2048, 28))\n",
    "\n",
    "    model = nn.Sequential(odict([('body', body), ('head', head)]))\n",
    "    \n",
    "    model.to(device_id)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_optimizer(model, lrs):\n",
    "    assert len(lrs) == 2\n",
    "    optimizer = optim.SGD([{'params': model.body.parameters(), 'lr': lrs[0]}, \n",
    "                       {'params': model.head.parameters(), 'lr': lrs[1]}],\n",
    "                       momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "def create_lr_scheduler(optimizer, num_epochs):\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: (1-epoch/num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('/home/xmiler/projects/human-protein-atlas-image-classification/input/')\n",
    "device_id = 0\n",
    "arch = models.resnet50(pretrained=True)\n",
    "\n",
    "dataloader = create_dataloader(root_dir)\n",
    "model = create_model(arch, device_id)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "lrs = [0., 0.01]\n",
    "\n",
    "optimizer = create_optimizer(model, lrs)\n",
    "lr_scheduler = create_lr_scheduler(optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "CPU times: user 9.99 s, sys: 3.77 s, total: 13.8 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "i = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device_id)\n",
    "        labels = labels.float().to(device_id)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "        if i == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "CPU times: user 16.8 s, sys: 1.5 s, total: 18.3 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "i = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device_id)\n",
    "        labels = labels.float().to(device_id)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "        if i == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6429, 0.6432, 0.6538, 0.6752, 0.6630, 0.6697, 0.6534, 0.6529, 0.6739,\n",
       "        0.6812, 0.6675, 0.6877, 0.6351, 0.6502, 0.6799, 0.6549],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(object):\n",
    "    def __init__(self, dataloader, model):\n",
    "        self._model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Learner at 0x7fcfc0060400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = Learner(model)\n",
    "\n",
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.weight', Parameter containing:\n",
       "  tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')),\n",
       " ('1.bias', Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model[1]\n",
    "list(a.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602],\n",
       "        [ 789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058],\n",
       "        [1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049],\n",
       "        [ 944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153],\n",
       "        [ 792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642],\n",
       "        [ 976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813],\n",
       "        [ 957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943],\n",
       "        [1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984],\n",
       "        [ 898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312],\n",
       "        [1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331],\n",
       "        [1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306],\n",
       "        [ 970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405],\n",
       "        [ 878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012],\n",
       "        [ 827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314],\n",
       "        [ 861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253],\n",
       "        [ 829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818]],\n",
       "       device='cuda:0', grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in model[1].named_parameters():    \n",
    "    p.requires_grad=False\n",
    "    p.zero_()\n",
    "    p.add_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0065,  0.0162,  0.0008,  ..., -0.0007,  0.0088,  0.0199],\n",
       "         [ 0.0014,  0.0108,  0.0013,  ...,  0.0128,  0.0136, -0.0143],\n",
       "         [ 0.0111, -0.0135, -0.0187,  ...,  0.0101,  0.0097, -0.0176],\n",
       "         ...,\n",
       "         [ 0.0117,  0.0012, -0.0014,  ...,  0.0136,  0.0100, -0.0203],\n",
       "         [-0.0044,  0.0208,  0.0154,  ...,  0.0043, -0.0022, -0.0016],\n",
       "         [ 0.0189,  0.0063,  0.0081,  ...,  0.0046,  0.0032, -0.0178]],\n",
       "        device='cuda:0', requires_grad=True), Parameter containing:\n",
       " tensor([-0.0074,  0.0008, -0.0100,  0.0185, -0.0091,  0.0027, -0.0005, -0.0007,\n",
       "          0.0039, -0.0182,  0.0052,  0.0001,  0.0020,  0.0053,  0.0140, -0.0090,\n",
       "         -0.0050, -0.0128,  0.0148, -0.0179,  0.0125,  0.0214,  0.0207,  0.0007,\n",
       "         -0.0009,  0.0099, -0.0030, -0.0009],\n",
       "        device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32768 x 1], m2: [2048 x 28] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a49b4583540d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32768 x 1], m2: [2048 x 28] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "c1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if n.startswith('fc'):\n",
    "        p.requires_grad=False\n",
    "        p.zero_()\n",
    "        p.add_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602,  984.3602,  984.3602,\n",
       "          984.3602,  984.3602,  984.3602,  984.3602],\n",
       "        [ 789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058,  789.5058,  789.5058,\n",
       "          789.5058,  789.5058,  789.5058,  789.5058],\n",
       "        [1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049, 1000.3049,\n",
       "         1000.3049, 1000.3049, 1000.3049, 1000.3049],\n",
       "        [ 944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153,  944.2153,  944.2153,\n",
       "          944.2153,  944.2153,  944.2153,  944.2153],\n",
       "        [ 792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642,  792.9642,  792.9642,\n",
       "          792.9642,  792.9642,  792.9642,  792.9642],\n",
       "        [ 976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813,  976.5813,  976.5813,\n",
       "          976.5813,  976.5813,  976.5813,  976.5813],\n",
       "        [ 957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943,  957.8943,  957.8943,\n",
       "          957.8943,  957.8943,  957.8943,  957.8943],\n",
       "        [1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984, 1049.5984,\n",
       "         1049.5984, 1049.5984, 1049.5984, 1049.5984],\n",
       "        [ 898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312,  898.5312,  898.5312,\n",
       "          898.5312,  898.5312,  898.5312,  898.5312],\n",
       "        [1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331, 1084.1331,\n",
       "         1084.1331, 1084.1331, 1084.1331, 1084.1331],\n",
       "        [1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306, 1003.1306,\n",
       "         1003.1306, 1003.1306, 1003.1306, 1003.1306],\n",
       "        [ 970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405,  970.8405,  970.8405,\n",
       "          970.8405,  970.8405,  970.8405,  970.8405],\n",
       "        [ 878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012,  878.1012,  878.1012,\n",
       "          878.1012,  878.1012,  878.1012,  878.1012],\n",
       "        [ 827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314,  827.7314,  827.7314,\n",
       "          827.7314,  827.7314,  827.7314,  827.7314],\n",
       "        [ 861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253,  861.2253,  861.2253,\n",
       "          861.2253,  861.2253,  861.2253,  861.2253],\n",
       "        [ 829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818,  829.8818,  829.8818,\n",
       "          829.8818,  829.8818,  829.8818,  829.8818]],\n",
       "       device='cuda:0', grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for p, _ in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n"
     ]
    }
   ],
   "source": [
    "for i, (a,b) in enumerate(model.named_children()):\n",
    "    print(a)\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.conv1.weight', Parameter containing:\n",
      "tensor([[[[ 0.0035]],\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[-0.0248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1028]],\n",
      "\n",
      "         [[-0.2893]],\n",
      "\n",
      "         [[-0.1518]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1149]],\n",
      "\n",
      "         [[ 0.0057]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0807]],\n",
      "\n",
      "         [[-0.0848]],\n",
      "\n",
      "         [[-0.1358]]],\n",
      "\n",
      "\n",
      "        [[[-0.0190]],\n",
      "\n",
      "         [[ 0.0112]],\n",
      "\n",
      "         [[-0.0160]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0715]],\n",
      "\n",
      "         [[ 0.0767]],\n",
      "\n",
      "         [[-0.0460]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0020]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         [[-0.0623]],\n",
      "\n",
      "         [[ 0.0094]]],\n",
      "\n",
      "\n",
      "        [[[-0.0528]],\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[-0.0061]],\n",
      "\n",
      "         [[ 0.0126]]],\n",
      "\n",
      "\n",
      "        [[[-0.0565]],\n",
      "\n",
      "         [[-0.1190]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0410]],\n",
      "\n",
      "         [[ 0.2449]],\n",
      "\n",
      "         [[-0.0079]]]], device='cuda:0', requires_grad=True))\n",
      "('0.bn1.weight', Parameter containing:\n",
      "tensor([2.1341e-01, 1.8848e-01, 1.4136e-01, 1.5273e-01, 1.3220e-01, 1.8735e-01,\n",
      "        1.4475e-01, 4.5110e-08, 1.5993e-01, 1.4946e-01, 2.3499e-01, 1.8315e-01,\n",
      "        1.8516e-01, 1.4933e-01, 1.3090e-01, 1.0634e-01, 3.7487e-01, 1.2644e-01,\n",
      "        3.1895e-01, 2.7160e-01, 2.5810e-01, 2.9458e-01, 1.8395e-01, 2.1088e-08,\n",
      "        3.3313e-01, 2.0461e-01, 3.0399e-01, 1.1805e-08, 1.4977e-01, 1.5719e-01,\n",
      "        1.4011e-01, 1.4900e-01, 1.2438e-01, 1.8786e-01, 1.4257e-01, 3.4828e-01,\n",
      "        1.5038e-01, 3.0034e-01, 2.5925e-01, 1.0711e-01, 2.6875e-01, 1.3552e-01,\n",
      "        1.1822e-01, 1.1189e-01, 2.8736e-01, 3.2637e-01, 1.4781e-01, 2.3105e-01,\n",
      "        3.3638e-01, 2.8808e-01, 1.2319e-01, 3.0763e-01, 1.1846e-01, 1.3137e-01,\n",
      "        2.0671e-01, 1.5787e-01, 2.6574e-08, 2.0467e-01, 2.8797e-08, 1.8284e-01,\n",
      "        3.0180e-01, 1.7401e-01, 2.8438e-01, 2.3715e-01],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.bn1.bias', Parameter containing:\n",
      "tensor([ 0.4327,  0.0469, -0.0801,  0.0733,  0.2797, -0.0078,  0.0941, -0.0000,\n",
      "        -0.1403, -0.0516,  0.0445,  0.2181,  0.0407,  0.1198,  0.1443,  0.1367,\n",
      "        -0.1117,  0.1477, -0.1288, -0.0531, -0.0339, -0.0206,  0.0628, -0.0000,\n",
      "        -0.0712,  0.0695, -0.1326, -0.0000, -0.0289,  0.0942,  0.2479, -0.0829,\n",
      "        -0.0289, -0.1709,  0.0995, -0.1136,  0.1977,  0.0148, -0.0709,  0.1072,\n",
      "         0.0125, -0.0366,  0.1496,  0.1053,  0.0209, -0.1050, -0.0488,  0.4901,\n",
      "        -0.1476, -0.1090,  0.0198, -0.0710, -0.0465,  0.1087, -0.2788,  0.0044,\n",
      "        -0.0000,  0.0751, -0.0000,  0.2253, -0.0716, -0.1582, -0.0345,  0.5289],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.conv2.weight', Parameter containing:\n",
      "tensor([[[[ 2.0919e-09, -1.4152e-09,  6.5850e-09],\n",
      "          [ 4.7922e-09,  3.2819e-09,  9.4284e-10],\n",
      "          [ 6.4763e-09, -3.0156e-09, -2.3958e-09]],\n",
      "\n",
      "         [[ 1.1471e-08,  1.2815e-08,  1.3568e-08],\n",
      "          [ 1.0737e-08,  4.9712e-09,  3.8516e-09],\n",
      "          [ 1.0572e-08,  1.2153e-08,  6.9175e-09]],\n",
      "\n",
      "         [[-6.8447e-09, -2.8470e-09, -1.5396e-09],\n",
      "          [ 4.8804e-09, -3.0935e-09,  2.3919e-09],\n",
      "          [ 5.2998e-09, -1.4133e-11, -7.5312e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4828e-09, -7.6425e-09, -9.5572e-09],\n",
      "          [-7.0080e-09, -4.0208e-09, -4.5819e-09],\n",
      "          [-4.9349e-09, -5.4604e-10, -1.3119e-08]],\n",
      "\n",
      "         [[-1.0458e-09, -6.9635e-09, -5.1090e-09],\n",
      "          [-3.4306e-10, -4.2656e-09, -2.2703e-09],\n",
      "          [-1.8570e-09, -4.8467e-09, -3.5571e-09]],\n",
      "\n",
      "         [[ 1.8746e-09,  8.6741e-10, -5.5741e-10],\n",
      "          [ 2.6233e-10, -5.0061e-09,  5.8350e-09],\n",
      "          [ 2.4322e-10,  1.6342e-10,  3.3284e-09]]],\n",
      "\n",
      "\n",
      "        [[[-2.3484e-02,  1.8706e-03,  2.5798e-02],\n",
      "          [ 3.5355e-03, -5.2646e-03,  1.9523e-02],\n",
      "          [ 2.4600e-02,  2.1933e-02,  1.6219e-04]],\n",
      "\n",
      "         [[-3.3788e-03,  3.2976e-03,  1.2707e-02],\n",
      "          [ 1.7570e-02,  1.5054e-02,  1.7517e-02],\n",
      "          [ 2.2276e-02,  2.2339e-02, -5.5213e-03]],\n",
      "\n",
      "         [[-3.8421e-03, -5.9462e-03,  1.5058e-02],\n",
      "          [-3.1875e-03, -2.5218e-02, -3.3736e-03],\n",
      "          [ 4.9239e-04, -1.9673e-02, -1.8729e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2840e-03,  6.6714e-03,  1.1301e-02],\n",
      "          [ 1.3283e-02,  9.0130e-03,  6.2237e-03],\n",
      "          [ 2.1055e-02,  1.5775e-02,  8.4497e-03]],\n",
      "\n",
      "         [[ 5.9612e-04,  2.7906e-03,  6.5433e-03],\n",
      "          [ 8.4950e-03,  9.2682e-02,  5.1201e-03],\n",
      "          [-9.0937e-03, -6.4196e-03, -2.7363e-04]],\n",
      "\n",
      "         [[-2.0518e-02, -4.6551e-03, -2.9206e-02],\n",
      "          [-1.1651e-02,  1.6589e-02, -1.8225e-03],\n",
      "          [-3.0077e-02,  4.2854e-03,  3.0994e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8186e-02,  4.5909e-02,  2.6377e-02],\n",
      "          [ 4.5241e-02,  6.5042e-02,  5.4767e-02],\n",
      "          [ 4.5518e-02,  5.9040e-02,  3.6224e-02]],\n",
      "\n",
      "         [[ 6.4452e-03, -9.0585e-04,  7.1830e-03],\n",
      "          [ 6.7971e-03,  6.3635e-03,  2.1455e-02],\n",
      "          [ 1.1262e-02,  1.6089e-02,  1.7535e-02]],\n",
      "\n",
      "         [[ 4.0125e-03, -1.5436e-02,  6.1919e-03],\n",
      "          [-1.6548e-02, -3.7222e-03,  2.9918e-02],\n",
      "          [-4.1074e-03, -4.8143e-03,  1.5329e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4917e-02,  1.9070e-02,  3.3504e-02],\n",
      "          [ 3.1252e-02, -7.5642e-03,  3.5888e-02],\n",
      "          [ 2.9346e-02,  3.3745e-02,  4.2878e-02]],\n",
      "\n",
      "         [[ 6.5392e-03, -1.6478e-02,  2.1843e-02],\n",
      "          [-1.3546e-02,  2.4295e-03,  6.9680e-03],\n",
      "          [ 3.1423e-03, -3.7818e-03,  3.2182e-03]],\n",
      "\n",
      "         [[ 7.3159e-03, -2.3604e-02, -1.1507e-02],\n",
      "          [-3.3326e-02, -4.4065e-02, -4.6069e-02],\n",
      "          [-3.1847e-02, -3.7215e-02, -2.4266e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8211e-09,  2.9120e-09, -5.6310e-09],\n",
      "          [ 4.3212e-09, -1.8635e-09, -3.3057e-09],\n",
      "          [ 2.2608e-09, -1.2302e-09,  1.6536e-10]],\n",
      "\n",
      "         [[ 1.9862e-09, -2.7085e-09, -1.5189e-08],\n",
      "          [ 9.0284e-09,  2.6774e-09, -2.3783e-09],\n",
      "          [ 5.4744e-09,  4.7255e-09, -5.1706e-09]],\n",
      "\n",
      "         [[ 4.2245e-10, -6.2215e-09, -7.1381e-09],\n",
      "          [-4.5743e-09, -8.9245e-09, -4.1074e-09],\n",
      "          [-1.7179e-09, -1.4299e-10, -4.7585e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6792e-09,  3.7950e-09,  5.4831e-10],\n",
      "          [-4.9152e-09, -9.4884e-09, -6.3708e-09],\n",
      "          [ 8.2731e-09,  3.9463e-09,  3.8983e-09]],\n",
      "\n",
      "         [[ 4.0006e-09, -1.3585e-09, -2.7413e-12],\n",
      "          [-1.2756e-09,  2.5309e-09, -4.6894e-09],\n",
      "          [ 4.9880e-10,  3.3068e-09, -8.5953e-09]],\n",
      "\n",
      "         [[ 2.7820e-09,  7.1263e-10,  3.2218e-09],\n",
      "          [ 3.4826e-09,  5.6161e-09, -3.8766e-09],\n",
      "          [ 2.3460e-09,  6.0292e-09,  4.8710e-10]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1531e-02,  5.8091e-02,  3.6932e-02],\n",
      "          [ 3.4071e-02, -1.3114e-02, -2.9585e-02],\n",
      "          [ 1.0524e-02, -3.7806e-02, -5.0393e-02]],\n",
      "\n",
      "         [[-7.4381e-03, -1.9210e-03, -3.3986e-03],\n",
      "          [ 1.3362e-02,  1.5364e-02, -1.0274e-03],\n",
      "          [-7.1327e-03, -2.5406e-02, -3.1194e-02]],\n",
      "\n",
      "         [[ 6.0968e-03, -1.9646e-02, -8.9450e-03],\n",
      "          [ 1.4864e-03, -1.2455e-02,  1.0394e-02],\n",
      "          [-2.6015e-03, -1.3369e-02,  1.5983e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0871e-03,  6.2054e-04, -6.2765e-03],\n",
      "          [-4.0756e-03, -1.3461e-02, -1.4281e-02],\n",
      "          [-1.0118e-02, -2.1184e-02, -1.2876e-02]],\n",
      "\n",
      "         [[ 2.3335e-03,  1.8122e-02,  1.0758e-03],\n",
      "          [ 1.1701e-02,  2.8367e-02,  6.5168e-03],\n",
      "          [-1.4372e-02,  1.6207e-02,  1.3691e-02]],\n",
      "\n",
      "         [[-6.2637e-02, -2.5556e-02,  4.6860e-03],\n",
      "          [-3.8629e-02,  3.0089e-02,  4.4090e-02],\n",
      "          [ 1.2748e-03,  7.1193e-02,  6.3498e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4771e-02, -3.8409e-02,  9.7917e-02],\n",
      "          [-1.7643e-01,  3.2383e-03,  2.8121e-01],\n",
      "          [-1.0757e-01, -4.9282e-02,  1.4446e-01]],\n",
      "\n",
      "         [[ 5.1254e-03,  1.9011e-03,  4.1052e-02],\n",
      "          [-3.4516e-02, -1.4285e-02,  2.9000e-02],\n",
      "          [-3.2176e-02, -3.1341e-03,  5.7282e-02]],\n",
      "\n",
      "         [[-3.8417e-02, -5.1169e-02, -2.7389e-02],\n",
      "          [-3.8442e-02, -1.0360e-01, -8.7211e-02],\n",
      "          [-4.4993e-02, -5.8818e-02, -3.8287e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1003e-02, -1.7952e-02,  6.6377e-03],\n",
      "          [-5.5188e-02, -1.3361e-03,  6.0603e-02],\n",
      "          [-1.4080e-02,  1.6523e-03,  2.5246e-02]],\n",
      "\n",
      "         [[ 2.2449e-03,  1.1214e-02,  1.3945e-02],\n",
      "          [-1.1470e-02, -6.9804e-03,  4.3370e-02],\n",
      "          [-1.2780e-02,  2.6532e-03,  6.3033e-02]],\n",
      "\n",
      "         [[ 1.9265e-01, -4.7934e-02, -1.4074e-01],\n",
      "          [ 3.7943e-01, -1.4166e-02, -3.0701e-01],\n",
      "          [ 2.4804e-01, -5.6059e-02, -1.9182e-01]]]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.bn2.weight', Parameter containing:\n",
      "tensor([2.3224e-08, 1.3805e-01, 2.4155e-01, 1.3627e-01, 1.1577e-01, 1.8789e-01,\n",
      "        1.2005e-01, 1.3625e-01, 1.7837e-01, 1.3934e-01, 1.0924e-01, 1.7452e-01,\n",
      "        1.3525e-01, 1.5064e-01, 1.3912e-01, 1.2596e-01, 1.5728e-01, 1.3527e-01,\n",
      "        2.2781e-01, 4.6913e-07, 2.7175e-01, 1.6913e-01, 2.0877e-01, 2.0823e-01,\n",
      "        1.5117e-01, 1.7594e-01, 1.7099e-01, 1.8060e-01, 1.8968e-01, 1.8072e-01,\n",
      "        1.5526e-01, 1.3217e-01, 1.5328e-01, 2.2601e-01, 1.4130e-01, 1.4350e-01,\n",
      "        1.5354e-01, 1.6157e-01, 1.7243e-01, 2.2057e-01, 2.0561e-01, 2.2331e-01,\n",
      "        1.7635e-01, 1.1320e-01, 1.7612e-01, 2.0285e-01, 1.0247e-01, 2.6118e-01,\n",
      "        1.6209e-01, 1.4597e-01, 1.6170e-01, 1.7936e-01, 1.8842e-01, 1.2481e-01,\n",
      "        1.9059e-01, 1.7148e-01, 2.0484e-01, 1.3645e-01, 1.7423e-01, 1.5198e-03,\n",
      "        1.7775e-01, 9.5639e-09, 1.7993e-01, 2.3351e-01],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.bn2.bias', Parameter containing:\n",
      "tensor([-0.0000,  0.0380,  0.3519,  0.1243,  0.2717,  0.3489,  0.2894,  0.1506,\n",
      "        -0.1400, -0.0892, -0.0285,  0.3179,  0.2828, -0.0344, -0.1381,  0.2829,\n",
      "         0.3712, -0.1096,  0.2203, -0.0000,  0.0844,  0.1409, -0.0422,  0.4286,\n",
      "         0.1098,  0.1743,  0.1697, -0.0261, -0.0561, -0.0295,  0.0740,  0.3102,\n",
      "         0.3401,  0.5250, -0.0029, -0.0962,  0.3945,  0.1647,  0.1009,  0.1088,\n",
      "         0.3678,  0.0797,  0.0642,  0.2253, -0.0556, -0.0598,  0.2722, -0.2281,\n",
      "         0.3871, -0.0277,  0.3776,  0.1444,  0.0857,  0.1683, -0.0041,  0.0203,\n",
      "        -0.2051, -0.0495, -0.1281, -0.0067, -0.0503, -0.0000, -0.0491,  0.0912],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.conv3.weight', Parameter containing:\n",
      "tensor([[[[-4.0119e-09]],\n",
      "\n",
      "         [[ 1.7726e-02]],\n",
      "\n",
      "         [[ 4.9594e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0813e-08]],\n",
      "\n",
      "         [[-1.7592e-02]],\n",
      "\n",
      "         [[-4.8830e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7415e-09]],\n",
      "\n",
      "         [[ 2.7212e-03]],\n",
      "\n",
      "         [[ 2.0600e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3281e-09]],\n",
      "\n",
      "         [[ 3.7770e-03]],\n",
      "\n",
      "         [[-3.4820e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.2345e-09]],\n",
      "\n",
      "         [[-1.2277e-05]],\n",
      "\n",
      "         [[-8.5743e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2814e-09]],\n",
      "\n",
      "         [[ 7.8754e-04]],\n",
      "\n",
      "         [[-1.1076e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1314e-09]],\n",
      "\n",
      "         [[-7.2828e-04]],\n",
      "\n",
      "         [[ 3.0347e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2589e-08]],\n",
      "\n",
      "         [[ 4.5773e-03]],\n",
      "\n",
      "         [[ 6.7829e-05]]],\n",
      "\n",
      "\n",
      "        [[[-7.4988e-09]],\n",
      "\n",
      "         [[-6.2381e-03]],\n",
      "\n",
      "         [[ 9.3970e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6372e-09]],\n",
      "\n",
      "         [[-4.9588e-02]],\n",
      "\n",
      "         [[ 1.0847e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4321e-09]],\n",
      "\n",
      "         [[-4.5942e-03]],\n",
      "\n",
      "         [[-1.7466e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1837e-09]],\n",
      "\n",
      "         [[ 2.9926e-02]],\n",
      "\n",
      "         [[-1.0834e-01]]]], device='cuda:0', requires_grad=True))\n",
      "('0.bn3.weight', Parameter containing:\n",
      "tensor([ 6.1257e-02,  3.2458e-04,  3.6922e-02,  3.1272e-01,  5.7752e-02,\n",
      "         5.3033e-02,  1.1429e-01,  3.8885e-01,  9.7341e-02,  1.8650e-01,\n",
      "         2.7582e-01,  1.8488e-01,  2.1568e-01,  2.1534e-01,  2.3184e-01,\n",
      "         1.6155e-01,  2.2608e-01,  3.4452e-01,  7.7296e-02,  1.5048e-01,\n",
      "         1.3025e-01,  2.1159e-01,  1.1078e-06,  9.5138e-09,  1.7439e-01,\n",
      "         4.9364e-04,  7.4613e-03,  2.7059e-01,  2.1378e-01,  2.0946e-01,\n",
      "         1.7827e-01,  3.3235e-01,  2.4776e-01,  1.8123e-01,  1.2957e-01,\n",
      "         2.0325e-01,  1.4420e-01,  2.1640e-01,  7.3485e-04,  2.2436e-02,\n",
      "        -1.1337e-02,  2.1912e-01,  1.7915e-01,  2.3578e-01,  1.2075e-01,\n",
      "         1.5954e-05,  8.8865e-02,  1.4537e-01,  8.8577e-02, -1.0227e-02,\n",
      "         2.1639e-01,  3.4835e-02,  1.6429e-07,  1.3006e-01,  7.1514e-02,\n",
      "         1.6472e-01,  7.2320e-03,  2.2837e-01,  1.8653e-01,  2.0731e-01,\n",
      "         1.6906e-01,  1.5374e-01,  1.6835e-01,  9.4061e-02,  7.8185e-08,\n",
      "         3.9745e-03,  8.6304e-02,  2.6490e-01,  1.6982e-01,  5.5553e-03,\n",
      "         2.8270e-02, -2.6206e-07,  2.6815e-01,  5.8706e-02,  3.1914e-01,\n",
      "         5.1964e-02,  9.1686e-04,  5.5850e-02,  2.8677e-01,  1.7436e-01,\n",
      "         2.1439e-01,  2.4483e-01,  1.6849e-01, -4.5969e-06,  2.4238e-01,\n",
      "         1.7576e-01,  1.4963e-01,  7.5519e-07,  1.7493e-01,  9.7360e-07,\n",
      "        -7.9266e-04,  5.9956e-02,  3.1109e-03,  3.9409e-04,  2.0501e-02,\n",
      "         8.4718e-02,  2.0573e-01,  2.8278e-01,  9.7521e-02,  1.1674e-01,\n",
      "         2.6729e-01,  3.7739e-07,  2.7196e-01,  1.0523e-01,  2.5316e-01,\n",
      "         1.0540e-01,  2.1283e-01,  7.0997e-07,  1.5051e-02,  2.5951e-01,\n",
      "         8.4987e-02,  2.1008e-01, -4.4472e-03, -9.5576e-02,  2.4416e-01,\n",
      "         2.6090e-01,  2.8566e-01,  1.6807e-08,  2.2492e-01,  2.8301e-01,\n",
      "         1.8392e-01,  2.0118e-01,  2.8446e-01,  1.7130e-05,  7.6160e-02,\n",
      "         2.1699e-01,  1.9139e-01,  1.6825e-05,  6.9757e-02,  2.0047e-01,\n",
      "         1.9512e-01,  1.4369e-01,  1.6181e-01,  1.0848e-06,  1.0534e-06,\n",
      "         1.7272e-02,  1.3205e-01,  5.6653e-02,  2.2185e-01,  9.6189e-02,\n",
      "         6.2859e-02,  3.1226e-01,  7.7507e-02,  1.2070e-01,  5.8322e-02,\n",
      "         2.3725e-01,  2.5693e-01,  1.1205e-01,  6.6947e-02,  1.5241e-01,\n",
      "         8.6475e-02,  6.2732e-02,  8.2831e-02, -8.1404e-02,  1.3252e-01,\n",
      "         1.3642e-01,  1.3644e-01,  1.4410e-01,  2.1566e-01, -1.1276e-01,\n",
      "         2.8843e-01,  2.2682e-01,  2.1664e-01, -1.8349e-02,  3.6098e-02,\n",
      "         1.3628e-02,  3.6618e-02,  2.6597e-01,  1.5605e-01,  1.1028e-01,\n",
      "        -1.6914e-02,  2.4349e-01,  1.2086e-01,  1.3346e-01,  1.1930e-05,\n",
      "         6.3407e-02,  2.4949e-01,  2.0691e-01,  1.6867e-01,  1.5140e-01,\n",
      "         1.6620e-01,  6.7047e-02,  1.4889e-01,  2.4088e-01, -6.1604e-03,\n",
      "        -1.7191e-06,  1.6970e-01,  2.7898e-01,  2.5087e-01,  7.2350e-06,\n",
      "         1.1479e-01,  3.0211e-03,  8.4946e-02,  1.8868e-01,  5.3232e-03,\n",
      "         9.9272e-02,  1.4196e-01,  2.1632e-01,  1.9907e-01,  1.5927e-05,\n",
      "         2.6186e-01,  3.2927e-01,  9.0553e-07,  2.8694e-01, -4.3297e-08,\n",
      "         3.2081e-03,  1.4184e-01, -9.3964e-02,  1.3650e-01,  2.2932e-01,\n",
      "         1.5370e-01, -1.0009e-01,  9.0725e-02,  1.5219e-01,  8.0811e-07,\n",
      "         2.5773e-01,  1.8997e-01,  1.8119e-01,  2.0239e-01,  2.5482e-01,\n",
      "        -2.8486e-04,  1.5002e-01,  7.8557e-02,  5.6243e-02,  6.7529e-02,\n",
      "         1.7906e-01, -8.9718e-04,  1.5554e-01,  4.1687e-03,  1.4187e-02,\n",
      "         1.5717e-01,  2.7333e-01,  3.5062e-02,  2.7199e-01,  2.0747e-01,\n",
      "         6.5914e-02,  1.5763e-01, -1.5537e-03,  6.2626e-02,  4.1613e-02,\n",
      "         1.0547e-01, -2.1628e-02, -4.1070e-03,  2.8397e-01,  1.7258e-01,\n",
      "         6.1170e-02, -1.5988e-05,  7.2228e-02,  1.1727e-01,  1.6374e-01,\n",
      "         2.1004e-01,  5.8066e-02,  2.6768e-01,  1.4760e-03,  2.9346e-01,\n",
      "         1.4359e-01], device='cuda:0', requires_grad=True))\n",
      "('0.bn3.bias', Parameter containing:\n",
      "tensor([-0.0048,  0.0734,  0.0299,  0.0542, -0.0421,  0.0457,  0.0704,  0.1361,\n",
      "         0.0960,  0.0868,  0.0466,  0.0088, -0.0056,  0.0356,  0.0602,  0.0295,\n",
      "         0.1149,  0.1002, -0.0706,  0.0579,  0.0591,  0.0320, -0.0000, -0.0000,\n",
      "         0.0955, -0.0012, -0.1064, -0.0077,  0.0433,  0.0102,  0.0333,  0.0107,\n",
      "         0.0505, -0.0252,  0.0580, -0.0395,  0.0243,  0.0246,  0.0191,  0.0874,\n",
      "        -0.0108,  0.0461, -0.0028,  0.0669,  0.0395, -0.0000,  0.0449,  0.0177,\n",
      "        -0.1175,  0.0378,  0.1149,  0.1171, -0.0000,  0.0372, -0.0409,  0.0816,\n",
      "         0.1449,  0.0060,  0.0242, -0.0136, -0.0517,  0.0548,  0.0463,  0.0223,\n",
      "        -0.0000,  0.0416,  0.0039,  0.0216, -0.0087,  0.0943, -0.0444, -0.0000,\n",
      "         0.2165,  0.0896,  0.0187,  0.0207, -0.0030, -0.2169,  0.0503,  0.0385,\n",
      "         0.0591,  0.0361,  0.0995, -0.0000,  0.1425,  0.1907,  0.0380, -0.0000,\n",
      "        -0.0054, -0.0000,  0.0986, -0.0942, -0.0413, -0.0083, -0.0288,  0.1067,\n",
      "         0.1556,  0.0279,  0.0531, -0.0312,  0.0395, -0.0000,  0.0030,  0.0355,\n",
      "         0.0799,  0.0238, -0.1298, -0.0000, -0.0672,  0.1734,  0.0958,  0.0918,\n",
      "        -0.0432,  0.0784, -0.0001,  0.0540,  0.0470, -0.0000,  0.1571,  0.0293,\n",
      "         0.0308, -0.1507,  0.0930, -0.0001,  0.1117,  0.0155,  0.0609, -0.0006,\n",
      "         0.0264,  0.0526,  0.1660, -0.0398,  0.0576, -0.0000, -0.0000,  0.1155,\n",
      "         0.0492, -0.0149,  0.0444, -0.0311, -0.0237,  0.0658,  0.0671,  0.0984,\n",
      "        -0.2378,  0.0330,  0.1902,  0.0163, -0.3074,  0.0312, -0.2164,  0.0119,\n",
      "        -0.0042,  0.0056, -0.0753,  0.0132,  0.0218,  0.0006,  0.0049, -0.0579,\n",
      "         0.0519,  0.1334, -0.0160,  0.1653, -0.0283,  0.0041,  0.0276,  0.0128,\n",
      "        -0.0015,  0.0295,  0.0863, -0.0408, -0.0326, -0.0154, -0.0000,  0.0106,\n",
      "         0.0354,  0.1242,  0.0777, -0.0111,  0.0190, -0.0584, -0.0172, -0.0492,\n",
      "         0.0116, -0.0000,  0.0139,  0.1085,  0.0685,  0.1767,  0.0356, -0.0403,\n",
      "         0.0462,  0.0335,  0.0223,  0.0467,  0.0292,  0.1038,  0.0280, -0.0000,\n",
      "         0.0836,  0.0796, -0.0000,  0.1276, -0.0000,  0.1128, -0.0104, -0.0050,\n",
      "         0.0913,  0.0502, -0.0195, -0.0003, -0.0302,  0.0771, -0.0000,  0.0707,\n",
      "         0.0236,  0.0358, -0.0637,  0.1049,  0.1138,  0.0013, -0.0491,  0.1154,\n",
      "        -0.0602,  0.0010,  0.0648,  0.0764,  0.0599,  0.1196, -0.0517,  0.0528,\n",
      "         0.0271,  0.0520,  0.1907,  0.0171,  0.0552,  0.1257, -0.0027, -0.0313,\n",
      "         0.0471,  0.0517, -0.0059,  0.0296,  0.1912,  0.0140, -0.0004,  0.0239,\n",
      "        -0.0366,  0.0352,  0.0826,  0.0692,  0.1178,  0.0343,  0.1947,  0.0327],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.downsample.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.0076]],\n",
      "\n",
      "         [[-0.1659]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         [[ 0.0014]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0128]],\n",
      "\n",
      "         [[-0.0115]],\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0004]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.0022]]],\n",
      "\n",
      "\n",
      "        [[[-0.0359]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         [[-0.0263]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0595]],\n",
      "\n",
      "         [[-0.0003]],\n",
      "\n",
      "         [[-0.0064]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0396]],\n",
      "\n",
      "         [[-0.3943]],\n",
      "\n",
      "         [[ 0.0728]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[ 0.1106]],\n",
      "\n",
      "         [[ 0.0165]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0015]],\n",
      "\n",
      "         [[ 0.0116]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0702]],\n",
      "\n",
      "         [[ 0.1604]],\n",
      "\n",
      "         [[ 0.0362]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0204]],\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[-0.0352]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1160]],\n",
      "\n",
      "         [[ 0.0242]],\n",
      "\n",
      "         [[-0.0506]]]], device='cuda:0', requires_grad=True))\n",
      "('0.downsample.1.weight', Parameter containing:\n",
      "tensor([ 2.4457e-01,  2.2984e-01,  1.4612e-01,  3.4260e-01,  2.5927e-02,\n",
      "         1.1437e-01,  2.1102e-01,  4.5606e-01,  1.8027e-01,  1.5431e-01,\n",
      "         3.5582e-01,  2.1846e-01,  2.5678e-01,  1.5123e-02,  4.0578e-01,\n",
      "         2.0874e-01,  9.8095e-02,  3.9442e-01,  1.9774e-01,  3.0000e-01,\n",
      "         2.4856e-01,  2.3178e-01, -1.0182e-08,  1.3827e-08,  3.1164e-01,\n",
      "         4.8934e-04,  2.6274e-01,  5.9192e-02,  1.9006e-01,  2.0053e-01,\n",
      "         1.6345e-01,  3.0634e-01,  3.5806e-01,  1.8923e-02,  3.0784e-01,\n",
      "         4.3668e-01,  2.7498e-01,  1.6151e-01,  2.9890e-01,  1.2460e-01,\n",
      "         7.0893e-02,  3.3482e-01,  3.4934e-01,  2.8829e-01,  2.7963e-01,\n",
      "         8.1415e-07,  3.6592e-01,  1.6732e-01,  2.2241e-01,  1.9294e-01,\n",
      "         2.9332e-01,  1.4812e-01,  2.0370e-07,  1.6793e-01,  2.2183e-01,\n",
      "         2.7442e-01, -1.1456e-02,  3.9355e-01,  2.5354e-01,  3.2749e-01,\n",
      "         3.3727e-01,  2.0058e-01,  2.4418e-01,  1.6629e-01,  2.0949e-08,\n",
      "         1.8675e-01,  1.8726e-01,  2.4386e-01,  1.7288e-01,  2.2883e-01,\n",
      "         1.9265e-01,  1.8148e-07,  1.8998e-01,  1.9738e-01,  3.0906e-01,\n",
      "         1.1432e-01,  2.7538e-03,  2.8674e-01,  2.9543e-01,  2.0380e-01,\n",
      "         2.9774e-01,  3.0047e-01,  3.0071e-01,  3.0339e-06,  2.5298e-01,\n",
      "         2.8255e-01,  2.3041e-01, -2.2464e-07,  9.0851e-02,  9.4888e-08,\n",
      "         2.3342e-01,  2.8756e-01,  2.5694e-01,  1.9065e-03,  1.9803e-02,\n",
      "         1.2581e-01,  2.5297e-01,  1.0138e-01,  1.9470e-01,  2.4283e-01,\n",
      "         2.2812e-01,  3.9112e-07,  4.3694e-01,  2.0982e-01,  3.3158e-01,\n",
      "         3.6135e-01,  1.6712e-01,  2.8431e-07,  2.4639e-01,  3.1374e-01,\n",
      "         2.0042e-01,  1.7867e-01,  2.4927e-01,  2.6893e-01,  2.4301e-02,\n",
      "         3.3343e-01,  2.8018e-01,  1.0910e-07,  3.1720e-01,  3.2437e-01,\n",
      "         1.7580e-01,  2.1966e-01,  2.2206e-01,  3.8821e-05,  2.1403e-01,\n",
      "         3.1898e-01,  2.2020e-01,  2.1191e-04,  2.4318e-01,  3.2712e-01,\n",
      "         3.5392e-01,  1.9045e-01,  2.4259e-01,  5.9542e-07,  2.1926e-06,\n",
      "         2.0136e-01,  2.0292e-01,  1.6009e-01,  3.1163e-01,  3.1269e-02,\n",
      "         1.5136e-01,  3.4167e-01,  2.2320e-01,  1.7928e-01,  3.0206e-01,\n",
      "         3.3896e-01,  3.2244e-01,  3.3214e-01,  3.1712e-01,  2.6545e-01,\n",
      "         3.4695e-01,  1.9813e-01,  1.5368e-01,  2.3095e-01,  1.2709e-01,\n",
      "         2.2131e-01,  7.9861e-02,  1.0763e-01,  3.4360e-01,  2.8470e-01,\n",
      "         3.1999e-01,  3.4235e-01,  2.8543e-01,  2.5500e-01,  8.0065e-02,\n",
      "         2.1822e-01,  1.2625e-01,  3.3813e-01,  3.6787e-01,  2.0902e-01,\n",
      "         7.5418e-02,  3.0735e-01,  4.3765e-02,  9.5508e-02, -3.7830e-06,\n",
      "         3.1341e-01,  2.3747e-01,  2.9429e-01,  1.7653e-01,  3.3874e-01,\n",
      "         2.2616e-01,  1.9847e-01,  3.5470e-01,  8.1458e-03,  2.0669e-01,\n",
      "         1.0625e-06,  3.6871e-01,  3.6358e-01,  1.9882e-01,  1.6871e-01,\n",
      "         3.9717e-01,  2.4319e-01,  2.2733e-01,  2.5196e-01,  4.8692e-02,\n",
      "         3.4219e-01,  3.5018e-01, -4.2149e-02,  1.8716e-01, -7.9278e-06,\n",
      "         2.8354e-01,  3.7017e-01,  1.4341e-07,  3.1774e-01,  7.5645e-08,\n",
      "         1.6309e-01,  1.6707e-01,  2.2129e-01,  2.7987e-01,  2.5573e-01,\n",
      "         2.8884e-01,  2.4309e-01,  8.3486e-02,  2.5541e-01,  6.3526e-07,\n",
      "         3.6438e-01,  2.3440e-01,  2.2243e-01,  3.1752e-01,  3.1876e-01,\n",
      "         2.5398e-01,  1.6543e-01,  6.8547e-02,  1.9213e-01,  1.8097e-01,\n",
      "         2.8546e-01,  2.0063e-01,  1.9390e-01,  2.0524e-01,  1.8420e-01,\n",
      "         2.0247e-02,  2.7564e-01,  1.4836e-01,  3.3919e-01,  1.8534e-01,\n",
      "         2.9466e-01,  2.7174e-01,  2.9968e-01,  1.3451e-01,  1.9264e-01,\n",
      "         1.2815e-01,  1.7942e-01,  3.1054e-01,  3.0394e-01,  3.0231e-01,\n",
      "         2.6601e-01,  7.0521e-05,  1.6745e-01,  2.4501e-01,  1.2502e-01,\n",
      "         3.6441e-01,  2.4699e-01,  3.7460e-01,  1.6707e-01,  3.6041e-01,\n",
      "         1.8811e-01], device='cuda:0', requires_grad=True))\n",
      "('0.downsample.1.bias', Parameter containing:\n",
      "tensor([-0.0048,  0.0734,  0.0299,  0.0542, -0.0421,  0.0457,  0.0704,  0.1361,\n",
      "         0.0960,  0.0868,  0.0466,  0.0088, -0.0056,  0.0356,  0.0602,  0.0295,\n",
      "         0.1149,  0.1002, -0.0706,  0.0579,  0.0591,  0.0320, -0.0000, -0.0000,\n",
      "         0.0955, -0.0012, -0.1064, -0.0077,  0.0433,  0.0102,  0.0333,  0.0107,\n",
      "         0.0505, -0.0252,  0.0580, -0.0395,  0.0243,  0.0246,  0.0191,  0.0874,\n",
      "        -0.0108,  0.0461, -0.0028,  0.0669,  0.0395, -0.0000,  0.0449,  0.0177,\n",
      "        -0.1175,  0.0378,  0.1149,  0.1171, -0.0000,  0.0372, -0.0409,  0.0816,\n",
      "         0.1449,  0.0060,  0.0242, -0.0136, -0.0517,  0.0548,  0.0463,  0.0223,\n",
      "        -0.0000,  0.0416,  0.0039,  0.0216, -0.0087,  0.0943, -0.0444, -0.0000,\n",
      "         0.2165,  0.0896,  0.0187,  0.0207, -0.0030, -0.2169,  0.0503,  0.0385,\n",
      "         0.0591,  0.0361,  0.0995, -0.0000,  0.1425,  0.1907,  0.0380, -0.0000,\n",
      "        -0.0054, -0.0000,  0.0986, -0.0942, -0.0413, -0.0083, -0.0288,  0.1067,\n",
      "         0.1556,  0.0279,  0.0531, -0.0312,  0.0395, -0.0000,  0.0030,  0.0355,\n",
      "         0.0799,  0.0238, -0.1298, -0.0000, -0.0672,  0.1734,  0.0958,  0.0918,\n",
      "        -0.0432,  0.0784, -0.0001,  0.0540,  0.0470, -0.0000,  0.1571,  0.0293,\n",
      "         0.0308, -0.1507,  0.0930, -0.0001,  0.1117,  0.0155,  0.0609, -0.0006,\n",
      "         0.0264,  0.0526,  0.1660, -0.0398,  0.0576, -0.0000, -0.0000,  0.1155,\n",
      "         0.0492, -0.0149,  0.0444, -0.0311, -0.0237,  0.0658,  0.0671,  0.0984,\n",
      "        -0.2378,  0.0330,  0.1902,  0.0163, -0.3074,  0.0312, -0.2164,  0.0119,\n",
      "        -0.0042,  0.0056, -0.0753,  0.0132,  0.0218,  0.0006,  0.0049, -0.0579,\n",
      "         0.0519,  0.1334, -0.0160,  0.1653, -0.0283,  0.0041,  0.0276,  0.0128,\n",
      "        -0.0015,  0.0295,  0.0863, -0.0408, -0.0326, -0.0154, -0.0000,  0.0106,\n",
      "         0.0354,  0.1242,  0.0777, -0.0111,  0.0190, -0.0584, -0.0172, -0.0492,\n",
      "         0.0116, -0.0000,  0.0139,  0.1085,  0.0685,  0.1767,  0.0356, -0.0403,\n",
      "         0.0462,  0.0335,  0.0223,  0.0467,  0.0292,  0.1038,  0.0280, -0.0000,\n",
      "         0.0836,  0.0796, -0.0000,  0.1276, -0.0000,  0.1128, -0.0104, -0.0050,\n",
      "         0.0913,  0.0502, -0.0195, -0.0003, -0.0302,  0.0771, -0.0000,  0.0707,\n",
      "         0.0236,  0.0358, -0.0637,  0.1049,  0.1138,  0.0013, -0.0491,  0.1154,\n",
      "        -0.0602,  0.0010,  0.0648,  0.0764,  0.0599,  0.1196, -0.0517,  0.0528,\n",
      "         0.0271,  0.0520,  0.1907,  0.0171,  0.0552,  0.1257, -0.0027, -0.0313,\n",
      "         0.0471,  0.0517, -0.0059,  0.0296,  0.1912,  0.0140, -0.0004,  0.0239,\n",
      "        -0.0366,  0.0352,  0.0826,  0.0692,  0.1178,  0.0343,  0.1947,  0.0327],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.conv1.weight', Parameter containing:\n",
      "tensor([[[[ 0.0250]],\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         [[ 0.0110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0004]],\n",
      "\n",
      "         [[ 0.0207]],\n",
      "\n",
      "         [[-0.0345]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0023]],\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[-0.0111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[-0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0060]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         [[-0.0386]],\n",
      "\n",
      "         [[ 0.0282]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0059]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0106]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[-0.0496]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0453]],\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         [[-0.0131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0219]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[-0.0212]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0066]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         [[ 0.0725]]]], device='cuda:0', requires_grad=True))\n",
      "('1.bn1.weight', Parameter containing:\n",
      "tensor([1.5418e-01, 3.2359e-01, 2.4792e-01, 2.1051e-01, 1.7820e-01, 1.8067e-01,\n",
      "        1.7301e-01, 2.4763e-01, 1.7234e-01, 3.1702e-01, 1.4758e-01, 1.9952e-01,\n",
      "        1.2419e-01, 1.2985e-09, 1.6273e-01, 1.9145e-01, 1.6043e-01, 1.9408e-01,\n",
      "        2.5509e-01, 1.7340e-01, 1.4120e-01, 1.7380e-01, 1.7927e-01, 1.2663e-01,\n",
      "        1.6290e-01, 1.0250e-01, 1.7276e-01, 1.5056e-01, 1.7809e-01, 2.2617e-01,\n",
      "        2.8132e-01, 2.1156e-01, 2.3651e-01, 1.8941e-01, 1.6280e-01, 1.5587e-01,\n",
      "        1.6888e-01, 2.4972e-01, 3.4105e-01, 1.3929e-01, 3.0862e-01, 3.0111e-01,\n",
      "        1.7055e-01, 2.9651e-01, 1.1900e-01, 4.6577e-07, 1.7862e-01, 1.4380e-08,\n",
      "        1.4639e-01, 1.9021e-01, 1.9271e-01, 2.1601e-01, 1.5010e-01, 2.4548e-01,\n",
      "        1.3231e-01, 2.9485e-01, 8.5831e-09, 1.7127e-01, 1.3440e-01, 1.4374e-01,\n",
      "        2.1540e-01, 1.3796e-01, 1.9064e-01, 1.8207e-01],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.bn1.bias', Parameter containing:\n",
      "tensor([ 0.0579, -0.2085, -0.1097, -0.0106, -0.0521, -0.0173, -0.0055, -0.2088,\n",
      "         0.0080, -0.4051,  0.0259, -0.0947,  0.0957, -0.0000,  0.0099, -0.0450,\n",
      "         0.0556,  0.0221, -0.1456, -0.2415, -0.0068,  0.0813,  0.0098,  0.0235,\n",
      "         0.1049,  0.0757, -0.0015,  0.2358, -0.0458, -0.0441, -0.1798,  0.0016,\n",
      "        -0.1049, -0.0986,  0.0194, -0.1021,  0.2773, -0.1427, -0.2283,  0.0141,\n",
      "        -0.1963, -0.2304, -0.1022, -0.1904,  0.2946, -0.0000, -0.1162, -0.0000,\n",
      "         0.1068, -0.2521, -0.0652, -0.0075,  0.1440, -0.0738,  0.2820, -0.1958,\n",
      "        -0.0000,  0.3923,  0.0956,  0.1174, -0.0165,  0.2502, -0.1617,  0.0096],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.conv2.weight', Parameter containing:\n",
      "tensor([[[[ 0.0151, -0.0021,  0.0132],\n",
      "          [ 0.0100, -0.0132, -0.0144],\n",
      "          [ 0.0021, -0.0128, -0.0029]],\n",
      "\n",
      "         [[-0.0106, -0.0032, -0.0094],\n",
      "          [ 0.0135,  0.0311,  0.0372],\n",
      "          [-0.0014, -0.0080, -0.0123]],\n",
      "\n",
      "         [[ 0.0036,  0.0165,  0.0109],\n",
      "          [ 0.0009,  0.0069,  0.0078],\n",
      "          [-0.0017, -0.0069,  0.0058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0181, -0.0385, -0.0229],\n",
      "          [ 0.0579,  0.0557,  0.0396],\n",
      "          [-0.0311, -0.0544, -0.0337]],\n",
      "\n",
      "         [[ 0.0113,  0.0306,  0.0083],\n",
      "          [ 0.0091,  0.0143,  0.0200],\n",
      "          [-0.0065,  0.0085, -0.0023]],\n",
      "\n",
      "         [[ 0.0011, -0.0097,  0.0048],\n",
      "          [ 0.0133, -0.0153, -0.0151],\n",
      "          [-0.0083, -0.0234, -0.0044]]],\n",
      "\n",
      "\n",
      "        [[[-0.0175, -0.0113,  0.0033],\n",
      "          [ 0.0087, -0.0133, -0.0019],\n",
      "          [ 0.0022, -0.0084, -0.0067]],\n",
      "\n",
      "         [[-0.0031, -0.0032,  0.0173],\n",
      "          [ 0.0624,  0.0462,  0.0464],\n",
      "          [ 0.0330,  0.0122,  0.0245]],\n",
      "\n",
      "         [[ 0.0011, -0.0185, -0.0121],\n",
      "          [ 0.0099,  0.0022, -0.0030],\n",
      "          [ 0.0004,  0.0053,  0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0017, -0.0125, -0.0180],\n",
      "          [ 0.0014,  0.0059, -0.0247],\n",
      "          [ 0.0135,  0.0208,  0.0097]],\n",
      "\n",
      "         [[-0.0049, -0.0250, -0.0422],\n",
      "          [ 0.0137, -0.0207, -0.0481],\n",
      "          [ 0.0246,  0.0150, -0.0302]],\n",
      "\n",
      "         [[-0.0033,  0.0017, -0.0011],\n",
      "          [-0.0099, -0.0029, -0.0032],\n",
      "          [ 0.0018, -0.0126, -0.0077]]],\n",
      "\n",
      "\n",
      "        [[[-0.0356,  0.0035,  0.0059],\n",
      "          [-0.0414,  0.0229, -0.0115],\n",
      "          [-0.0294,  0.0026,  0.0048]],\n",
      "\n",
      "         [[-0.0338, -0.0395, -0.0470],\n",
      "          [-0.0515, -0.0658, -0.0412],\n",
      "          [-0.0307, -0.0409, -0.0323]],\n",
      "\n",
      "         [[-0.0037,  0.0104, -0.0045],\n",
      "          [-0.0079, -0.0176,  0.0188],\n",
      "          [-0.0087, -0.0215,  0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0045,  0.0167, -0.0235],\n",
      "          [-0.0151,  0.0316, -0.0012],\n",
      "          [ 0.0003,  0.0122, -0.0108]],\n",
      "\n",
      "         [[ 0.0130, -0.0031, -0.0026],\n",
      "          [ 0.0146, -0.0110, -0.0187],\n",
      "          [ 0.0083, -0.0069, -0.0082]],\n",
      "\n",
      "         [[-0.0031,  0.0023, -0.0355],\n",
      "          [ 0.0295,  0.0369, -0.0165],\n",
      "          [-0.0213, -0.0020, -0.0381]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0190, -0.0020,  0.0119],\n",
      "          [ 0.0338,  0.0030,  0.0158],\n",
      "          [ 0.0240,  0.0196,  0.0078]],\n",
      "\n",
      "         [[ 0.0124,  0.0085,  0.0201],\n",
      "          [ 0.0220, -0.0002,  0.0139],\n",
      "          [ 0.0170,  0.0108,  0.0325]],\n",
      "\n",
      "         [[ 0.0069,  0.0246,  0.0210],\n",
      "          [ 0.0136,  0.0189,  0.0089],\n",
      "          [ 0.0329,  0.0042, -0.0077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0111, -0.0069, -0.0239],\n",
      "          [ 0.0213,  0.0218, -0.0291],\n",
      "          [-0.0280, -0.0239, -0.0415]],\n",
      "\n",
      "         [[ 0.0113, -0.0042, -0.0185],\n",
      "          [-0.0292, -0.0325,  0.0032],\n",
      "          [-0.0158,  0.0015, -0.0003]],\n",
      "\n",
      "         [[ 0.0173, -0.0139,  0.0008],\n",
      "          [ 0.0143, -0.0308, -0.0010],\n",
      "          [ 0.0049,  0.0144,  0.0411]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0459,  0.0371,  0.0130],\n",
      "          [ 0.0213,  0.0062, -0.0190],\n",
      "          [ 0.0094, -0.0246, -0.0104]],\n",
      "\n",
      "         [[ 0.0027,  0.0145,  0.0010],\n",
      "          [ 0.0018,  0.0008,  0.0048],\n",
      "          [ 0.0068,  0.0143,  0.0046]],\n",
      "\n",
      "         [[-0.0016,  0.0038,  0.0338],\n",
      "          [-0.0014,  0.0155,  0.0617],\n",
      "          [ 0.0331,  0.0448,  0.0330]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0120,  0.0110, -0.0403],\n",
      "          [ 0.0010,  0.0172, -0.0262],\n",
      "          [-0.0156,  0.0454, -0.0266]],\n",
      "\n",
      "         [[-0.0076,  0.0040,  0.0109],\n",
      "          [-0.0105, -0.0056,  0.0258],\n",
      "          [-0.0093,  0.0169,  0.0254]],\n",
      "\n",
      "         [[ 0.0215,  0.0032, -0.0204],\n",
      "          [ 0.0341, -0.0177, -0.0323],\n",
      "          [-0.0232, -0.0267, -0.0178]]],\n",
      "\n",
      "\n",
      "        [[[-0.0336, -0.0059, -0.0499],\n",
      "          [ 0.0044, -0.0812, -0.0100],\n",
      "          [-0.0212,  0.0124, -0.0075]],\n",
      "\n",
      "         [[-0.0342,  0.0167, -0.0014],\n",
      "          [-0.0088,  0.0600,  0.0059],\n",
      "          [-0.0219, -0.0056, -0.0184]],\n",
      "\n",
      "         [[ 0.0129,  0.0154,  0.0076],\n",
      "          [ 0.0152,  0.0089,  0.0163],\n",
      "          [ 0.0236,  0.0142,  0.0150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0241,  0.0082, -0.0027],\n",
      "          [ 0.0207, -0.0857,  0.0213],\n",
      "          [ 0.0015,  0.0217,  0.0123]],\n",
      "\n",
      "         [[ 0.0338,  0.0042,  0.0167],\n",
      "          [ 0.0034, -0.0850,  0.0261],\n",
      "          [ 0.0072, -0.0106,  0.0101]],\n",
      "\n",
      "         [[ 0.0216,  0.0137, -0.0019],\n",
      "          [ 0.0285, -0.0227, -0.0092],\n",
      "          [ 0.0433,  0.0103,  0.0143]]]], device='cuda:0', requires_grad=True))\n",
      "('1.bn2.weight', Parameter containing:\n",
      "tensor([0.3002, 0.1879, 0.1683, 0.1700, 0.2510, 0.1264, 0.1596, 0.1925, 0.1379,\n",
      "        0.1619, 0.1925, 0.2059, 0.2133, 0.1886, 0.1552, 0.1556, 0.2230, 0.2143,\n",
      "        0.1503, 0.2025, 0.1546, 0.1728, 0.1657, 0.1653, 0.1759, 0.2397, 0.1492,\n",
      "        0.1925, 0.1350, 0.1303, 0.2352, 0.2116, 0.2162, 0.1721, 0.1860, 0.2056,\n",
      "        0.1355, 0.2451, 0.1831, 0.2053, 0.1650, 0.1824, 0.2217, 0.1820, 0.2021,\n",
      "        0.1699, 0.2040, 0.1753, 0.1816, 0.1904, 0.1531, 0.2186, 0.1661, 0.1781,\n",
      "        0.1438, 0.2048, 0.1353, 0.1997, 0.2582, 0.1683, 0.1852, 0.1189, 0.1655,\n",
      "        0.1964], device='cuda:0', requires_grad=True))\n",
      "('1.bn2.bias', Parameter containing:\n",
      "tensor([-0.3349, -0.1008, -0.0095,  0.0479, -0.0964,  0.3131,  0.0501, -0.0227,\n",
      "         0.2577,  0.1367, -0.1260, -0.0017, -0.1620, -0.0494,  0.1925,  0.0733,\n",
      "        -0.0646, -0.1330,  0.0037, -0.1173,  0.0661, -0.1220,  0.0396,  0.0579,\n",
      "         0.0875, -0.2095,  0.2687, -0.1505,  0.2573,  0.2496, -0.0825,  0.0500,\n",
      "        -0.0324, -0.0489,  0.0205,  0.0002,  0.1885, -0.0236, -0.0888, -0.0540,\n",
      "        -0.2141, -0.0731, -0.0511, -0.0304, -0.0897, -0.0896, -0.1392,  0.0069,\n",
      "        -0.1228, -0.1339,  0.0683, -0.0021, -0.0092, -0.0254,  0.2965,  0.0168,\n",
      "         0.1691, -0.0496, -0.1790,  0.1099,  0.0447,  0.1081, -0.0762, -0.0343],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.conv3.weight', Parameter containing:\n",
      "tensor([[[[ 0.0624]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0055]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[-0.0074]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0961]],\n",
      "\n",
      "         [[ 0.0072]],\n",
      "\n",
      "         [[-0.0030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0006]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.0032]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0507]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[-0.0154]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         [[ 0.0089]],\n",
      "\n",
      "         [[ 0.0260]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0679]],\n",
      "\n",
      "         [[-0.0011]],\n",
      "\n",
      "         [[-0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0005]],\n",
      "\n",
      "         [[ 0.0053]],\n",
      "\n",
      "         [[-0.0038]]],\n",
      "\n",
      "\n",
      "        [[[-0.0193]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         [[ 0.0206]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[-0.0138]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0458]],\n",
      "\n",
      "         [[-0.0555]],\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         [[-0.0198]],\n",
      "\n",
      "         [[-0.0386]]]], device='cuda:0', requires_grad=True))\n",
      "('1.bn3.weight', Parameter containing:\n",
      "tensor([ 2.1259e-03, -6.9715e-03,  9.4608e-02, -1.1439e-02,  1.4931e-01,\n",
      "         1.6228e-03,  1.9745e-01,  1.8000e-02, -1.7183e-04,  1.1793e-01,\n",
      "         1.0572e-02,  1.5288e-01,  6.2277e-03, -9.6050e-04,  1.0127e-01,\n",
      "         1.4762e-01,  1.1484e-01,  2.5359e-02,  9.5329e-02,  2.8729e-03,\n",
      "         7.1651e-02,  2.7586e-03,  1.5039e-01,  2.7510e-01,  9.0146e-02,\n",
      "         1.2768e-01,  5.5667e-03,  1.3082e-01, -1.9346e-03,  5.0423e-02,\n",
      "         2.1226e-03, -7.5048e-03,  1.8880e-02,  1.1878e-01,  9.8673e-02,\n",
      "         7.3502e-02,  1.5206e-01,  8.6612e-02,  5.0623e-03, -1.2326e-03,\n",
      "         1.1257e-01,  5.9433e-02,  1.4774e-01,  8.9319e-02,  9.7549e-02,\n",
      "         6.0202e-02,  8.6732e-02,  1.5079e-01,  8.0304e-02,  2.7696e-02,\n",
      "        -1.7456e-02,  1.7293e-01,  6.8518e-02,  1.4533e-01,  4.0339e-03,\n",
      "         2.5851e-02,  1.8742e-01,  6.8096e-02,  1.0810e-01,  1.1762e-01,\n",
      "         5.3549e-03,  7.9646e-02, -2.2026e-03,  1.5807e-01,  7.9670e-08,\n",
      "         3.1757e-05,  1.1837e-01,  3.6327e-02,  1.5932e-01,  3.8934e-02,\n",
      "         1.2485e-01,  6.9955e-06,  4.1722e-02, -1.8706e-03,  2.6218e-02,\n",
      "         1.5290e-01,  2.1404e-01,  1.1172e-01, -4.6150e-03,  1.1622e-01,\n",
      "         8.1356e-02,  4.0980e-02,  4.7201e-02,  4.9864e-02,  9.7825e-02,\n",
      "         7.0251e-02,  1.0111e-01,  7.0747e-02, -7.6863e-05,  3.2789e-04,\n",
      "         2.4123e-03,  1.1639e-01,  2.5553e-03,  1.1059e-01,  2.2347e-01,\n",
      "         1.6373e-01,  5.5450e-03,  1.1086e-01,  1.6115e-01,  1.3622e-01,\n",
      "         1.0025e-01,  1.9535e-06,  7.9823e-02,  4.2133e-03,  2.5824e-02,\n",
      "         1.2685e-01,  1.5052e-01,  9.5539e-02,  7.1596e-04,  6.7004e-02,\n",
      "         5.2219e-03,  5.9135e-02,  1.8622e-03,  5.1936e-02,  1.3801e-01,\n",
      "        -1.0016e-02,  2.3089e-03,  1.5128e-01,  5.8505e-02,  1.8369e-03,\n",
      "         1.3944e-01,  1.8065e-01,  1.2049e-01, -2.3750e-05,  1.6272e-01,\n",
      "         5.0985e-02,  1.4397e-01, -4.7397e-05,  7.9884e-02,  5.2822e-02,\n",
      "         1.1337e-01,  1.5378e-01,  1.0323e-01,  1.5092e-01,  8.5652e-02,\n",
      "         1.3144e-01,  8.7746e-02,  1.4908e-01,  1.1047e-01,  1.5284e-01,\n",
      "         1.2085e-01,  8.5849e-03,  5.9879e-02,  1.0519e-01,  5.8930e-02,\n",
      "         7.4151e-02, -4.9627e-03,  1.2280e-01, -1.1367e-01,  7.9317e-02,\n",
      "         1.2471e-02,  7.1211e-02,  2.1419e-01,  5.7342e-02,  7.2397e-02,\n",
      "         1.8971e-01,  1.3408e-01,  2.0415e-01,  2.4954e-03,  1.2848e-03,\n",
      "         8.5444e-04,  6.0994e-02,  1.9005e-03,  3.4890e-03,  1.7403e-01,\n",
      "         1.9638e-01,  1.8264e-01,  5.0056e-03,  1.0441e-01,  1.1164e-01,\n",
      "         2.0009e-01,  1.5155e-02,  1.8996e-01,  1.4341e-01,  1.5146e-01,\n",
      "         8.5111e-02,  8.0783e-02,  1.6485e-03,  1.0222e-01,  1.4608e-01,\n",
      "        -5.9042e-02, -1.8772e-03,  1.3604e-01,  1.9610e-01,  2.5466e-03,\n",
      "         2.1734e-06, -6.8739e-03,  4.4865e-03,  5.7102e-02, -5.8736e-03,\n",
      "         1.7767e-01,  9.2354e-04, -3.2072e-03,  2.2485e-02,  2.0056e-01,\n",
      "         4.5350e-03,  9.2664e-02,  8.6701e-02,  6.1892e-02,  1.6515e-01,\n",
      "         1.3486e-02,  8.1960e-02,  1.8972e-06,  2.1170e-02,  1.7591e-01,\n",
      "        -2.7518e-04,  1.5886e-01,  5.5978e-02,  7.8433e-02,  9.7138e-02,\n",
      "         8.8362e-02, -5.5156e-02,  1.8277e-01,  1.0541e-01,  1.7125e-01,\n",
      "         2.3317e-02,  1.0716e-01,  1.0549e-01,  7.3666e-02,  7.0549e-02,\n",
      "         3.6463e-03,  8.2517e-02,  1.3419e-01, -2.9456e-03,  1.0492e-01,\n",
      "         1.1982e-01,  1.6136e-04,  5.0766e-02,  1.9301e-03,  1.5054e-01,\n",
      "         1.1902e-01, -2.0978e-03,  1.9658e-01,  4.5569e-03,  6.8229e-02,\n",
      "         1.3388e-02,  1.8132e-01, -5.9605e-04,  1.6247e-01,  3.2930e-02,\n",
      "         1.1200e-01,  1.9393e-01,  2.5808e-03,  8.3123e-02,  1.1253e-01,\n",
      "         1.7063e-01,  1.0440e-01,  1.7874e-01,  7.7854e-02,  1.5666e-01,\n",
      "         5.0905e-02, -2.7906e-03,  6.0902e-03,  8.2056e-04,  2.6993e-02,\n",
      "         2.0848e-01], device='cuda:0', requires_grad=True))\n",
      "('1.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0040,  0.0050, -0.0655,  0.0019, -0.0492,  0.0025,  0.0633, -0.0062,\n",
      "         0.0023,  0.0410, -0.0136,  0.0921,  0.0515,  0.0083, -0.0380,  0.0286,\n",
      "        -0.0330, -0.0031, -0.0964,  0.0025,  0.0182,  0.0001,  0.0635,  0.0194,\n",
      "        -0.0314, -0.0556,  0.0054,  0.0103,  0.0038, -0.0344, -0.0020,  0.0078,\n",
      "         0.0271,  0.1125,  0.0944,  0.1098, -0.1056, -0.0226,  0.0033,  0.0032,\n",
      "        -0.0248, -0.0237, -0.0322, -0.0712,  0.0313,  0.0413,  0.0213, -0.0615,\n",
      "        -0.1150,  0.0594,  0.0130,  0.0928, -0.0494,  0.0074,  0.0018, -0.0042,\n",
      "         0.1455, -0.0489, -0.0772, -0.0008,  0.0093, -0.0405,  0.0033,  0.0607,\n",
      "        -0.0000,  0.0050, -0.0614,  0.0366, -0.0658,  0.0054, -0.0440, -0.0001,\n",
      "         0.0405,  0.0040, -0.0085,  0.0727,  0.0409, -0.0508,  0.0061, -0.0182,\n",
      "         0.0020,  0.0516,  0.0086,  0.0974,  0.1243,  0.0912,  0.0548, -0.0247,\n",
      "         0.0083, -0.0027,  0.0011,  0.0094,  0.0019,  0.0066,  0.0950,  0.0526,\n",
      "         0.0059, -0.0535,  0.1038,  0.1338,  0.0077, -0.0000, -0.0008,  0.0023,\n",
      "         0.0061, -0.0310, -0.1476, -0.0311,  0.0018,  0.0174,  0.0025,  0.1163,\n",
      "         0.0024,  0.0044,  0.0533, -0.0062,  0.0031, -0.0034,  0.0055,  0.0035,\n",
      "        -0.0779, -0.1323, -0.0626, -0.0005, -0.0175,  0.0343,  0.0233, -0.0008,\n",
      "        -0.0754,  0.0051, -0.0400, -0.0104,  0.0312, -0.0159, -0.0749, -0.0189,\n",
      "        -0.0162, -0.0535,  0.0552, -0.1110, -0.0443,  0.0027, -0.0107,  0.0162,\n",
      "        -0.1024, -0.0506,  0.0138,  0.0131, -0.0316,  0.0151, -0.0830, -0.0427,\n",
      "        -0.0526,  0.0030,  0.0590,  0.0539, -0.0169,  0.0095,  0.0023,  0.0038,\n",
      "         0.0075,  0.0003,  0.0082,  0.0023,  0.0231,  0.0346, -0.0831,  0.0095,\n",
      "        -0.0184,  0.0219,  0.1560,  0.0070, -0.0139, -0.0286, -0.0276, -0.1129,\n",
      "        -0.0283,  0.0047,  0.0196,  0.0938,  0.0044, -0.0093,  0.0397,  0.0442,\n",
      "         0.0035, -0.0000, -0.0029,  0.0614, -0.0046,  0.0048, -0.0581,  0.0050,\n",
      "         0.0036, -0.0000,  0.0197,  0.0006, -0.0046,  0.0059, -0.0366, -0.0353,\n",
      "        -0.0036,  0.0039, -0.0000,  0.0105, -0.0335,  0.0032, -0.0217,  0.0661,\n",
      "         0.0200,  0.1392,  0.0114, -0.0671,  0.0365, -0.0245, -0.1483,  0.0071,\n",
      "        -0.0230,  0.0194,  0.0215, -0.0259,  0.0062, -0.0386,  0.0326,  0.0065,\n",
      "         0.1127, -0.0310,  0.0049, -0.0036,  0.0074,  0.0529, -0.0451,  0.0068,\n",
      "         0.0965,  0.0035,  0.0465, -0.0005, -0.1125,  0.0094,  0.0373, -0.0169,\n",
      "        -0.0072,  0.1263,  0.0050, -0.0484,  0.0017, -0.0274, -0.0723, -0.0857,\n",
      "        -0.0594,  0.0019,  0.0122,  0.0037,  0.0065,  0.0066,  0.0293, -0.0704],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('2.conv1.weight', Parameter containing:\n",
      "tensor([[[[ 0.0058]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0041]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0043]],\n",
      "\n",
      "         [[-0.0411]],\n",
      "\n",
      "         [[-0.0385]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0020]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[ 0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         [[-0.1166]],\n",
      "\n",
      "         [[ 0.0711]]],\n",
      "\n",
      "\n",
      "        [[[-0.0139]],\n",
      "\n",
      "         [[ 0.0018]],\n",
      "\n",
      "         [[ 0.0225]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0229]],\n",
      "\n",
      "         [[-0.0111]],\n",
      "\n",
      "         [[ 0.0073]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0025]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[-0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0124]],\n",
      "\n",
      "         [[-0.0116]],\n",
      "\n",
      "         [[ 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0004]],\n",
      "\n",
      "         [[ 0.0052]],\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0142]],\n",
      "\n",
      "         [[ 0.0658]],\n",
      "\n",
      "         [[-0.0233]]],\n",
      "\n",
      "\n",
      "        [[[-0.0025]],\n",
      "\n",
      "         [[-0.0001]],\n",
      "\n",
      "         [[-0.0332]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.0290]],\n",
      "\n",
      "         [[-0.0131]]]], device='cuda:0', requires_grad=True))\n",
      "('2.bn1.weight', Parameter containing:\n",
      "tensor([0.1913, 0.1692, 0.0998, 0.1557, 0.2209, 0.2088, 0.1592, 0.1858, 0.1681,\n",
      "        0.1715, 0.2173, 0.1619, 0.1758, 0.2133, 0.2372, 0.1801, 0.2278, 0.1665,\n",
      "        0.1719, 0.1989, 0.1980, 0.1442, 0.1775, 0.2147, 0.1963, 0.1785, 0.1716,\n",
      "        0.1923, 0.1763, 0.2147, 0.1436, 0.1808, 0.1411, 0.2095, 0.1432, 0.2235,\n",
      "        0.1475, 0.2037, 0.1705, 0.1889, 0.1268, 0.2000, 0.2031, 0.1841, 0.1522,\n",
      "        0.1639, 0.2384, 0.1928, 0.1385, 0.1841, 0.1849, 0.1573, 0.2080, 0.1951,\n",
      "        0.2446, 0.1780, 0.1835, 0.1956, 0.1273, 0.2016, 0.1753, 0.1431, 0.2104,\n",
      "        0.1973], device='cuda:0', requires_grad=True))\n",
      "('2.bn1.bias', Parameter containing:\n",
      "tensor([-0.0211, -0.0407, -0.0112, -0.1323, -0.1030, -0.0420, -0.0627,  0.0480,\n",
      "         0.0803,  0.1414, -0.1111, -0.1918,  0.0786, -0.0938, -0.1518,  0.0853,\n",
      "        -0.1570,  0.1497,  0.0868, -0.0677, -0.0525,  0.1388,  0.0777, -0.0986,\n",
      "         0.0222,  0.0800,  0.0634,  0.0124, -0.0755, -0.1144,  0.0747, -0.0626,\n",
      "         0.1637, -0.0787,  0.1791, -0.0868,  0.1491, -0.0757,  0.0105, -0.1133,\n",
      "        -0.0680,  0.0583, -0.0410, -0.0515,  0.0492, -0.0792, -0.1330, -0.0540,\n",
      "         0.0605, -0.1405, -0.0211,  0.1586, -0.1310, -0.0853, -0.1872,  0.0526,\n",
      "        -0.0925, -0.0578,  0.0782, -0.1039, -0.0210,  0.0612, -0.1123, -0.0781],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('2.conv2.weight', Parameter containing:\n",
      "tensor([[[[ 0.0331, -0.0023, -0.0261],\n",
      "          [-0.0019, -0.0141, -0.0076],\n",
      "          [-0.0496,  0.0285, -0.0120]],\n",
      "\n",
      "         [[ 0.0208, -0.0608,  0.0177],\n",
      "          [ 0.0223, -0.0532,  0.0273],\n",
      "          [-0.0186,  0.0073, -0.0045]],\n",
      "\n",
      "         [[ 0.0113,  0.0043,  0.0208],\n",
      "          [-0.0023, -0.0177,  0.0182],\n",
      "          [-0.0060, -0.0096,  0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0137, -0.0122, -0.0047],\n",
      "          [-0.0033, -0.0038, -0.0217],\n",
      "          [-0.0247,  0.0240, -0.0158]],\n",
      "\n",
      "         [[-0.0423,  0.0056,  0.0107],\n",
      "          [-0.0474,  0.0378,  0.0213],\n",
      "          [-0.0095,  0.0117, -0.0062]],\n",
      "\n",
      "         [[ 0.0031, -0.0079, -0.0253],\n",
      "          [ 0.0085, -0.0067, -0.0128],\n",
      "          [ 0.0073, -0.0168, -0.0076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0210, -0.0199, -0.0253],\n",
      "          [-0.0003,  0.0196, -0.0205],\n",
      "          [ 0.0463,  0.0772, -0.0554]],\n",
      "\n",
      "         [[-0.0372,  0.0679, -0.0338],\n",
      "          [-0.0548,  0.0633, -0.0324],\n",
      "          [-0.0053, -0.0111, -0.0008]],\n",
      "\n",
      "         [[ 0.0299, -0.0054,  0.0098],\n",
      "          [-0.0034,  0.0012, -0.0046],\n",
      "          [-0.0054, -0.0091,  0.0031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0180,  0.0242,  0.0079],\n",
      "          [-0.0087,  0.0216, -0.0065],\n",
      "          [-0.0227,  0.0089,  0.0222]],\n",
      "\n",
      "         [[ 0.0062, -0.0195, -0.0128],\n",
      "          [ 0.0185, -0.0134,  0.0000],\n",
      "          [ 0.0018, -0.0055,  0.0311]],\n",
      "\n",
      "         [[-0.0148,  0.0167, -0.0314],\n",
      "          [-0.0001,  0.0275,  0.0250],\n",
      "          [ 0.0077,  0.0026, -0.0216]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141,  0.0080, -0.0171],\n",
      "          [ 0.0038, -0.0250, -0.0270],\n",
      "          [ 0.0288,  0.0190, -0.0087]],\n",
      "\n",
      "         [[ 0.0090,  0.0112,  0.0278],\n",
      "          [ 0.0034, -0.0662,  0.0257],\n",
      "          [ 0.0375, -0.0212, -0.0284]],\n",
      "\n",
      "         [[ 0.0124,  0.0052, -0.0059],\n",
      "          [ 0.0146, -0.0124, -0.0028],\n",
      "          [-0.0008, -0.0025, -0.0067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0140,  0.0215,  0.0503],\n",
      "          [-0.0698, -0.0086,  0.0269],\n",
      "          [-0.0478, -0.0663,  0.0354]],\n",
      "\n",
      "         [[-0.0012, -0.0227, -0.0078],\n",
      "          [-0.0334,  0.0296, -0.0839],\n",
      "          [-0.0122,  0.0225,  0.0083]],\n",
      "\n",
      "         [[-0.0016,  0.0199, -0.0059],\n",
      "          [ 0.0099, -0.0044,  0.0139],\n",
      "          [-0.0050,  0.0211, -0.0023]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0495, -0.0025,  0.0024],\n",
      "          [-0.0254,  0.0026,  0.0132],\n",
      "          [-0.0284,  0.0062, -0.0007]],\n",
      "\n",
      "         [[-0.0016, -0.0137,  0.0165],\n",
      "          [-0.0077, -0.0384,  0.0419],\n",
      "          [-0.0008, -0.0208,  0.0086]],\n",
      "\n",
      "         [[ 0.0276,  0.0094,  0.0122],\n",
      "          [ 0.0208,  0.0027, -0.0042],\n",
      "          [ 0.0274,  0.0008, -0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0415, -0.0259,  0.0274],\n",
      "          [-0.0661, -0.0417,  0.0599],\n",
      "          [-0.0614,  0.0254,  0.0390]],\n",
      "\n",
      "         [[ 0.0621,  0.0057,  0.0001],\n",
      "          [-0.0191, -0.0326, -0.0342],\n",
      "          [-0.0228, -0.0094, -0.0148]],\n",
      "\n",
      "         [[-0.0270, -0.0245, -0.0139],\n",
      "          [-0.0426, -0.0368,  0.0616],\n",
      "          [-0.0386, -0.0022,  0.0424]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075, -0.0159,  0.0259],\n",
      "          [ 0.0262, -0.0192, -0.0066],\n",
      "          [-0.0000, -0.0105, -0.0013]],\n",
      "\n",
      "         [[-0.0050,  0.0115, -0.0397],\n",
      "          [-0.0128,  0.0174, -0.0264],\n",
      "          [ 0.0323,  0.0120, -0.0158]],\n",
      "\n",
      "         [[ 0.0312,  0.0041,  0.0111],\n",
      "          [-0.0029, -0.0041, -0.0049],\n",
      "          [ 0.0043, -0.0057,  0.0078]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0254,  0.0165,  0.0514],\n",
      "          [-0.0390,  0.0349,  0.0101],\n",
      "          [-0.0445,  0.0332, -0.0245]],\n",
      "\n",
      "         [[-0.0241, -0.0194, -0.0102],\n",
      "          [-0.0161,  0.0020,  0.0530],\n",
      "          [-0.0012,  0.0245,  0.0066]],\n",
      "\n",
      "         [[-0.0053, -0.0029,  0.0291],\n",
      "          [ 0.0153,  0.0064, -0.0094],\n",
      "          [ 0.0370, -0.0005, -0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0095,  0.0187,  0.0048],\n",
      "          [ 0.0272, -0.0340,  0.0149],\n",
      "          [-0.0434,  0.0190, -0.0109]],\n",
      "\n",
      "         [[ 0.0039, -0.0106, -0.0129],\n",
      "          [ 0.0142,  0.0170,  0.0154],\n",
      "          [-0.0262, -0.0123,  0.0320]],\n",
      "\n",
      "         [[ 0.0116,  0.0002,  0.0036],\n",
      "          [ 0.0079,  0.0270,  0.0097],\n",
      "          [-0.0014, -0.0003,  0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0409, -0.0126,  0.0053],\n",
      "          [ 0.0198, -0.0315, -0.0498],\n",
      "          [ 0.0157,  0.0472, -0.0218]],\n",
      "\n",
      "         [[-0.0119, -0.0164,  0.0043],\n",
      "          [ 0.0218, -0.0335, -0.0153],\n",
      "          [-0.0002,  0.0367, -0.0168]],\n",
      "\n",
      "         [[-0.0162,  0.0171,  0.0019],\n",
      "          [-0.0137,  0.0227,  0.0077],\n",
      "          [ 0.0242, -0.0099, -0.0089]]]], device='cuda:0', requires_grad=True))\n",
      "('2.bn2.weight', Parameter containing:\n",
      "tensor([0.2164, 0.2510, 0.2231, 0.2292, 0.2206, 0.2179, 0.2162, 0.1634, 0.2093,\n",
      "        0.2222, 0.2535, 0.3154, 0.2342, 0.2426, 0.2290, 0.2137, 0.2216, 0.1808,\n",
      "        0.2402, 0.2401, 0.2296, 0.2416, 0.2316, 0.2086, 0.2435, 0.2377, 0.2285,\n",
      "        0.2185, 0.2242, 0.2128, 0.2328, 0.2420, 0.1663, 0.2489, 0.1979, 0.2088,\n",
      "        0.2402, 0.1934, 0.1159, 0.2452, 0.2377, 0.1765, 0.2250, 0.1855, 0.2238,\n",
      "        0.2285, 0.2402, 0.2207, 0.2157, 0.2389, 0.2259, 0.2190, 0.2020, 0.2269,\n",
      "        0.2276, 0.2248, 0.2533, 0.1996, 0.2053, 0.1992, 0.2117, 0.2513, 0.2136,\n",
      "        0.2317], device='cuda:0', requires_grad=True))\n",
      "('2.bn2.bias', Parameter containing:\n",
      "tensor([-0.0306, -0.0923, -0.0414, -0.0653, -0.1028, -0.0986, -0.0136, -0.0025,\n",
      "        -0.1152, -0.0291, -0.0657, -0.3410, -0.0687, -0.0501, -0.0541, -0.0482,\n",
      "        -0.0685,  0.0415, -0.0591, -0.0672, -0.0274, -0.1126, -0.0099, -0.0306,\n",
      "        -0.1327, -0.0547, -0.0480, -0.0265, -0.0448, -0.0258, -0.0761, -0.1036,\n",
      "         0.0966, -0.0771,  0.0057, -0.0256, -0.1545,  0.1036,  0.2601, -0.1233,\n",
      "        -0.0618,  0.0686, -0.0530,  0.0247, -0.0409, -0.0814, -0.0808, -0.0434,\n",
      "        -0.0131, -0.0899, -0.0204, -0.0730, -0.0149, -0.0785, -0.0759, -0.1011,\n",
      "        -0.0613, -0.1066,  0.0035,  0.0221, -0.0881, -0.0364, -0.0522, -0.0728],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('2.conv3.weight', Parameter containing:\n",
      "tensor([[[[ 0.0043]],\n",
      "\n",
      "         [[-0.0028]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0021]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[ 0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0011]],\n",
      "\n",
      "         [[ 0.0030]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0025]],\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         [[-0.0066]]],\n",
      "\n",
      "\n",
      "        [[[-0.0199]],\n",
      "\n",
      "         [[-0.0104]],\n",
      "\n",
      "         [[-0.0676]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0245]],\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         [[-0.1256]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0013]],\n",
      "\n",
      "         [[ 0.0002]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         [[ 0.0084]],\n",
      "\n",
      "         [[ 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0002]],\n",
      "\n",
      "         [[ 0.0035]],\n",
      "\n",
      "         [[-0.0059]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[-0.0030]]],\n",
      "\n",
      "\n",
      "        [[[-0.0474]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0097]],\n",
      "\n",
      "         [[-0.0294]],\n",
      "\n",
      "         [[-0.0360]]]], device='cuda:0', requires_grad=True))\n",
      "('2.bn3.weight', Parameter containing:\n",
      "tensor([-0.0016,  0.0039,  0.2425,  0.0131,  0.2001, -0.0003,  0.1157,  0.0469,\n",
      "        -0.0015, -0.0213, -0.0027,  0.1475,  0.2144, -0.0070,  0.1194,  0.1255,\n",
      "         0.0041,  0.0799, -0.0005, -0.0005,  0.1292,  0.0793,  0.1562,  0.1081,\n",
      "         0.0817,  0.2245,  0.0016,  0.0518, -0.0021, -0.0041,  0.0056,  0.0016,\n",
      "        -0.0075,  0.0553,  0.1322, -0.0045,  0.0022, -0.0048, -0.0034,  0.0023,\n",
      "         0.3502,  0.0166,  0.1343,  0.0087, -0.0022,  0.2173,  0.0004,  0.1888,\n",
      "         0.2450,  0.1921, -0.0156,  0.0434,  0.2315,  0.1878,  0.0056,  0.0068,\n",
      "         0.0010,  0.1202,  0.0016,  0.0038,  0.0165,  0.0038, -0.0037,  0.0034,\n",
      "         0.3755,  0.0010,  0.2073,  0.0140,  0.0614,  0.0004,  0.1475,  0.2578,\n",
      "         0.0643, -0.0057, -0.0029,  0.0920,  0.1271,  0.0208, -0.0058,  0.0505,\n",
      "         0.0009, -0.0069,  0.0040,  0.2250,  0.1074,  0.1481,  0.1807,  0.2502,\n",
      "        -0.0038,  0.2358, -0.0017,  0.0852,  0.0010,  0.2784,  0.1446,  0.0625,\n",
      "         0.0034,  0.1425,  0.0004,  0.0504,  0.0321,  0.2767,  0.1396,  0.0061,\n",
      "         0.0592,  0.0856,  0.1206,  0.2202,  0.0017, -0.0057, -0.0030,  0.0022,\n",
      "         0.0006,  0.0117,  0.0708,  0.0683,  0.0196,  0.1942,  0.1436, -0.0469,\n",
      "         0.0319, -0.0979,  0.0079,  0.3327, -0.0042,  0.0008,  0.1136,  0.3380,\n",
      "         0.1424,  0.0981,  0.1345,  0.0581,  0.1317,  0.2326,  0.1753, -0.0130,\n",
      "         0.1274,  0.1846,  0.0102,  0.1972,  0.1870, -0.0045,  0.0482,  0.1322,\n",
      "        -0.0003,  0.0024,  0.0184,  0.0478,  0.0400,  0.1090,  0.0005,  0.1481,\n",
      "         0.1863,  0.1207,  0.0002,  0.1088,  0.0022,  0.1066,  0.0067, -0.0003,\n",
      "         0.0016,  0.0525,  0.0004,  0.0073,  0.1850,  0.0008,  0.1266,  0.0059,\n",
      "         0.0487,  0.2174,  0.0690,  0.0029,  0.1675,  0.2123,  0.1973,  0.1488,\n",
      "         0.0617,  0.0012,  0.1072,  0.1278,  0.2105,  0.0081,  0.0629,  0.0711,\n",
      "        -0.0027,  0.1726,  0.0000,  0.0759,  0.0108,  0.0019,  0.0082, -0.0008,\n",
      "         0.0039, -0.0305,  0.1661, -0.0016,  0.0711,  0.0164, -0.0029,  0.1796,\n",
      "         0.0242,  0.0327,  0.2187,  0.0048,  0.1950,  0.0014,  0.1541,  0.1010,\n",
      "         0.0469,  0.0230,  0.1238,  0.2172,  0.1265,  0.0617,  0.0626,  0.0042,\n",
      "         0.1738,  0.1467,  0.0994,  0.0942, -0.0024,  0.1659,  0.1885,  0.0002,\n",
      "         0.0056,  0.0617, -0.0044,  0.0083,  0.0039,  0.0799,  0.2456, -0.0040,\n",
      "         0.0625,  0.0030, -0.0019,  0.0058,  0.1215, -0.0049,  0.0302,  0.0103,\n",
      "         0.0873,  0.0342, -0.0005, -0.0038,  0.0264, -0.0051,  0.2376,  0.1021,\n",
      "         0.1778,  0.1523, -0.0035,  0.0004, -0.0009, -0.0003, -0.0130,  0.1728],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('2.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0017,  0.0050, -0.0054,  0.0124, -0.0881,  0.0005, -0.0247, -0.0418,\n",
      "         0.0035, -0.0235,  0.0070, -0.1078,  0.0535,  0.0057, -0.0897,  0.0597,\n",
      "         0.0052, -0.0405, -0.0603,  0.0030, -0.0492, -0.0297, -0.0631, -0.0590,\n",
      "        -0.0582, -0.0576,  0.0020,  0.0795,  0.0040,  0.0065, -0.0154,  0.0020,\n",
      "         0.0045,  0.0028, -0.0064,  0.0042,  0.0097,  0.0084,  0.0023,  0.0032,\n",
      "        -0.0188,  0.0164, -0.1280,  0.0127,  0.0017,  0.0174,  0.0038, -0.0713,\n",
      "         0.0007,  0.0770,  0.0008,  0.0517,  0.1328, -0.0958,  0.0005,  0.0035,\n",
      "         0.0027, -0.0058,  0.0045,  0.0072,  0.0020,  0.0050, -0.0005,  0.0033,\n",
      "        -0.0338,  0.0036,  0.0159,  0.0020, -0.0928,  0.0044, -0.0422,  0.0695,\n",
      "        -0.0106,  0.0024,  0.0076, -0.0066,  0.1455, -0.0577,  0.0016, -0.0517,\n",
      "         0.0034,  0.0016,  0.0090,  0.0579,  0.0588,  0.0985, -0.0513,  0.0631,\n",
      "         0.0069,  0.1254,  0.0027, -0.0781,  0.0034, -0.0169, -0.1071, -0.0529,\n",
      "         0.0066, -0.1662, -0.0032,  0.0389, -0.0090,  0.0724, -0.1217,  0.0030,\n",
      "        -0.0496, -0.0649, -0.0251,  0.1595,  0.0010,  0.0062,  0.0007,  0.0025,\n",
      "         0.0030,  0.0086, -0.1288, -0.0311,  0.0082,  0.0761, -0.0557,  0.0083,\n",
      "        -0.0369, -0.1549, -0.0042,  0.0209,  0.0010,  0.0079, -0.1325, -0.0068,\n",
      "         0.1754, -0.0212, -0.1287, -0.0491, -0.0283, -0.0692,  0.1399, -0.0108,\n",
      "        -0.0215,  0.0905,  0.0083,  0.1152,  0.0094, -0.0001, -0.0542, -0.0691,\n",
      "        -0.0366,  0.0085,  0.0077, -0.0154, -0.0710,  0.0421,  0.0052, -0.0696,\n",
      "        -0.0764,  0.0922,  0.0041, -0.1396,  0.0024, -0.1090,  0.0033,  0.0044,\n",
      "         0.0022, -0.0410,  0.0007,  0.0006, -0.0503,  0.0026, -0.1579,  0.0064,\n",
      "        -0.0523, -0.0934,  0.0422,  0.0069, -0.1208, -0.0240, -0.0178,  0.0259,\n",
      "        -0.0662,  0.0054, -0.0769, -0.0720, -0.0847, -0.0050, -0.0666, -0.1055,\n",
      "         0.0026,  0.1969,  0.0033,  0.0615,  0.0110,  0.0044,  0.0070,  0.0049,\n",
      "         0.0041, -0.0257,  0.0801,  0.0021, -0.0666,  0.0033,  0.0020,  0.0068,\n",
      "        -0.0105, -0.0078,  0.1224,  0.0045, -0.0717,  0.0086, -0.0488,  0.1549,\n",
      "        -0.0310,  0.0254, -0.0505,  0.0710, -0.0475,  0.0025, -0.0973,  0.0013,\n",
      "        -0.0858, -0.1063, -0.0699, -0.0341,  0.0053, -0.1138,  0.0241,  0.0034,\n",
      "         0.0031, -0.0646,  0.0038,  0.0027,  0.0046,  0.0062, -0.1204,  0.0027,\n",
      "        -0.0078, -0.0002,  0.0036,  0.0062, -0.1684,  0.0071, -0.0300, -0.0249,\n",
      "        -0.0095,  0.0118,  0.0034,  0.0103, -0.0524,  0.0034,  0.0167, -0.1474,\n",
      "         0.0302, -0.0559,  0.0060,  0.0043,  0.0034,  0.0053,  0.0052, -0.1542],\n",
      "       device='cuda:0', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for a in b.named_parameters():\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv1.weight', Parameter containing:\n",
       " tensor([[[[ 0.0133,  0.0147, -0.0154,  ..., -0.0409, -0.0430, -0.0708],\n",
       "           [ 0.0041,  0.0058,  0.0149,  ...,  0.0022, -0.0209, -0.0385],\n",
       "           [ 0.0223,  0.0236,  0.0161,  ...,  0.1028,  0.0626,  0.0520],\n",
       "           ...,\n",
       "           [-0.0009,  0.0278, -0.0101,  ..., -0.1272, -0.0766,  0.0078],\n",
       "           [ 0.0036,  0.0480,  0.0621,  ...,  0.0243, -0.0337, -0.0157],\n",
       "           [-0.0800, -0.0322, -0.0178,  ...,  0.0354,  0.0224,  0.0017]],\n",
       " \n",
       "          [[-0.0185,  0.0114,  0.0239,  ...,  0.0537,  0.0440, -0.0095],\n",
       "           [-0.0077,  0.0189,  0.0680,  ...,  0.1596,  0.1461,  0.1200],\n",
       "           [-0.0460, -0.0761, -0.0896,  ...,  0.1211,  0.1670,  0.1762],\n",
       "           ...,\n",
       "           [ 0.0288,  0.0137, -0.0838,  ..., -0.3808, -0.3041, -0.1397],\n",
       "           [ 0.0829,  0.1386,  0.1524,  ..., -0.0051, -0.1244, -0.1297],\n",
       "           [-0.0073,  0.0770,  0.1400,  ...,  0.1843,  0.1114,  0.0234]],\n",
       " \n",
       "          [[-0.0183, -0.0056,  0.0087,  ...,  0.0258,  0.0264, -0.0040],\n",
       "           [-0.0101,  0.0042,  0.0497,  ...,  0.1245,  0.1195,  0.1120],\n",
       "           [-0.0635, -0.1015, -0.0983,  ...,  0.1063,  0.1398,  0.1494],\n",
       "           ...,\n",
       "           [ 0.0258,  0.0105, -0.0746,  ..., -0.3138, -0.2549, -0.1228],\n",
       "           [ 0.0730,  0.1117,  0.1309,  ..., -0.0065, -0.1255, -0.1245],\n",
       "           [-0.0064,  0.0664,  0.1218,  ...,  0.1907,  0.1141,  0.0233]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0686,  0.0380,  0.0536,  ...,  0.0269,  0.0484,  0.0633],\n",
       "           [ 0.0618,  0.0184,  0.0227,  ..., -0.0488, -0.0221, -0.0057],\n",
       "           [ 0.0566,  0.0149, -0.0069,  ..., -0.1292, -0.0950, -0.0587],\n",
       "           ...,\n",
       "           [ 0.0238, -0.0523, -0.1128,  ..., -0.2559, -0.2405, -0.2032],\n",
       "           [ 0.0562, -0.0218, -0.0592,  ..., -0.2381, -0.1984, -0.1658],\n",
       "           [ 0.0596,  0.0037, -0.0487,  ..., -0.1610, -0.1434, -0.1025]],\n",
       " \n",
       "          [[-0.0990, -0.0721, -0.0727,  ..., -0.0362, -0.0819, -0.0881],\n",
       "           [-0.0706, -0.0392, -0.0105,  ...,  0.0595,  0.0259, -0.0133],\n",
       "           [-0.0940, -0.0253,  0.0307,  ...,  0.2074,  0.1616,  0.0869],\n",
       "           ...,\n",
       "           [-0.0400,  0.0641,  0.1694,  ...,  0.4581,  0.3784,  0.2587],\n",
       "           [-0.0650,  0.0136,  0.1301,  ...,  0.3666,  0.3201,  0.2044],\n",
       "           [-0.1043, -0.0272,  0.0412,  ...,  0.2280,  0.1862,  0.1185]],\n",
       " \n",
       "          [[ 0.0427,  0.0473,  0.0178,  ...,  0.0347,  0.0286,  0.0432],\n",
       "           [ 0.0363,  0.0335, -0.0012,  ...,  0.0043,  0.0047,  0.0250],\n",
       "           [ 0.0235,  0.0168, -0.0153,  ..., -0.0729, -0.0720, -0.0237],\n",
       "           ...,\n",
       "           [ 0.0296,  0.0018, -0.0796,  ..., -0.1814, -0.1695, -0.0612],\n",
       "           [ 0.0352, -0.0085, -0.0543,  ..., -0.1507, -0.1275, -0.0453],\n",
       "           [ 0.0548,  0.0398, -0.0105,  ..., -0.0423, -0.0522,  0.0005]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0073,  0.0157, -0.0002,  ..., -0.0325, -0.0313, -0.0302],\n",
       "           [ 0.0086,  0.0246,  0.0112,  ..., -0.0106, -0.0150, -0.0341],\n",
       "           [ 0.0078,  0.0313,  0.0251,  ...,  0.0125, -0.0006, -0.0054],\n",
       "           ...,\n",
       "           [-0.0011,  0.0134,  0.0011,  ...,  0.0366,  0.0468,  0.0752],\n",
       "           [-0.0153,  0.0081, -0.0007,  ...,  0.0037,  0.0198,  0.0750],\n",
       "           [-0.0196, -0.0019, -0.0069,  ..., -0.0033,  0.0290,  0.0876]],\n",
       " \n",
       "          [[ 0.0128,  0.0089,  0.0023,  ...,  0.0135,  0.0360,  0.0484],\n",
       "           [ 0.0142,  0.0117, -0.0030,  ...,  0.0272,  0.0519,  0.0387],\n",
       "           [ 0.0032,  0.0051, -0.0093,  ...,  0.0411,  0.0545,  0.0451],\n",
       "           ...,\n",
       "           [-0.0170, -0.0429, -0.0846,  ..., -0.0492, -0.0239,  0.0026],\n",
       "           [-0.0028, -0.0088, -0.0481,  ..., -0.0864, -0.0716, -0.0234],\n",
       "           [ 0.0288,  0.0230, -0.0047,  ..., -0.0508, -0.0395, -0.0071]],\n",
       " \n",
       "          [[ 0.0094, -0.0360, -0.0317,  ...,  0.0035,  0.0432,  0.0451],\n",
       "           [-0.0119, -0.0583, -0.0630,  ..., -0.0177,  0.0159, -0.0077],\n",
       "           [ 0.0142, -0.0338, -0.0501,  ..., -0.0021,  0.0061, -0.0080],\n",
       "           ...,\n",
       "           [ 0.0081, -0.0499, -0.0903,  ..., -0.0876, -0.0995, -0.1092],\n",
       "           [ 0.0188, -0.0144, -0.0467,  ..., -0.1119, -0.1451, -0.1444],\n",
       "           [ 0.0578,  0.0173, -0.0058,  ..., -0.0744, -0.1131, -0.1243]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0156,  0.0204,  0.0357,  ...,  0.0072,  0.0455, -0.0077],\n",
       "           [-0.0218,  0.0561,  0.0607,  ..., -0.0569,  0.0852, -0.0267],\n",
       "           [-0.0476,  0.1069,  0.0757,  ..., -0.0880,  0.1516, -0.0321],\n",
       "           ...,\n",
       "           [ 0.0015,  0.1255, -0.0493,  ...,  0.0591,  0.1576, -0.0412],\n",
       "           [ 0.0050,  0.0626, -0.0588,  ...,  0.0473,  0.0824, -0.0460],\n",
       "           [ 0.0162,  0.0054, -0.0658,  ...,  0.0510,  0.0465, -0.0168]],\n",
       " \n",
       "          [[ 0.0102,  0.0446,  0.0015,  ..., -0.0665,  0.0457,  0.0485],\n",
       "           [ 0.0045,  0.1287,  0.0301,  ..., -0.1464,  0.1474,  0.0837],\n",
       "           [ 0.0056,  0.2175,  0.0309,  ..., -0.1803,  0.2611,  0.0942],\n",
       "           ...,\n",
       "           [ 0.0465,  0.1946, -0.1389,  ...,  0.0438,  0.2858,  0.0517],\n",
       "           [ 0.0254,  0.0944, -0.1360,  ...,  0.0555,  0.1571, -0.0139],\n",
       "           [ 0.0162,  0.0292, -0.1051,  ...,  0.0726,  0.0824, -0.0104]],\n",
       " \n",
       "          [[ 0.0008,  0.0220,  0.0120,  ..., -0.0393,  0.0079,  0.0113],\n",
       "           [-0.0267,  0.0760,  0.0651,  ..., -0.0535,  0.0776,  0.0155],\n",
       "           [-0.0432,  0.1244,  0.0786,  ..., -0.0724,  0.1367, -0.0038],\n",
       "           ...,\n",
       "           [-0.0049,  0.1217, -0.0500,  ...,  0.0408,  0.1278, -0.0273],\n",
       "           [-0.0058,  0.0661, -0.0498,  ...,  0.0385,  0.0695, -0.0439],\n",
       "           [ 0.0034,  0.0330, -0.0427,  ...,  0.0434,  0.0335, -0.0300]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0458,  0.0523,  0.0449,  ..., -0.0294,  0.0046,  0.0144],\n",
       "           [ 0.0525,  0.0512,  0.0480,  ..., -0.1127, -0.0825, -0.0255],\n",
       "           [ 0.0903,  0.0773,  0.0673,  ..., -0.2145, -0.1115, -0.0172],\n",
       "           ...,\n",
       "           [ 0.0327,  0.0001, -0.1534,  ..., -0.2554, -0.1145,  0.0421],\n",
       "           [ 0.0192, -0.0279, -0.1479,  ..., -0.2487, -0.0302,  0.0824],\n",
       "           [-0.0066, -0.0572, -0.1515,  ..., -0.1868,  0.0098,  0.0984]],\n",
       " \n",
       "          [[-0.0031,  0.0120,  0.0169,  ...,  0.0048,  0.0048, -0.0009],\n",
       "           [ 0.0195,  0.0152,  0.0347,  ..., -0.0043, -0.0133, -0.0052],\n",
       "           [ 0.0202,  0.0112,  0.0506,  ..., -0.0654, -0.0064,  0.0186],\n",
       "           ...,\n",
       "           [-0.0111,  0.0106, -0.0424,  ..., -0.0482, -0.0282,  0.0464],\n",
       "           [ 0.0076,  0.0113, -0.0135,  ..., -0.0666,  0.0105,  0.0363],\n",
       "           [ 0.0098,  0.0064, -0.0002,  ..., -0.0309,  0.0265,  0.0301]],\n",
       " \n",
       "          [[-0.0424, -0.0232, -0.0225,  ...,  0.0147,  0.0122, -0.0211],\n",
       "           [-0.0294, -0.0257,  0.0015,  ...,  0.0428,  0.0215, -0.0056],\n",
       "           [-0.0395, -0.0451,  0.0150,  ...,  0.0306,  0.0414, -0.0077],\n",
       "           ...,\n",
       "           [-0.0313,  0.0078,  0.0160,  ...,  0.0632,  0.0049, -0.0298],\n",
       "           [-0.0129,  0.0168,  0.0484,  ...,  0.0463,  0.0266, -0.0416],\n",
       "           [-0.0171,  0.0073,  0.0482,  ...,  0.0354,  0.0144, -0.0473]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0198, -0.0283,  0.0616,  ..., -0.0527,  0.0098,  0.0050],\n",
       "           [-0.0462,  0.0537, -0.0266,  ...,  0.0192, -0.0220, -0.0132],\n",
       "           [ 0.0529, -0.0442, -0.0375,  ..., -0.2137, -0.0022,  0.0344],\n",
       "           ...,\n",
       "           [-0.0357,  0.0937,  0.1191,  ...,  0.5243, -0.0454, -0.0592],\n",
       "           [-0.0114,  0.1008, -0.1985,  ...,  0.2335, -0.2630,  0.1243],\n",
       "           [-0.0141,  0.0052, -0.0757,  ..., -0.0567,  0.0337, -0.0342]],\n",
       " \n",
       "          [[ 0.0186, -0.0391,  0.0415,  ..., -0.0423,  0.0274, -0.0053],\n",
       "           [-0.0453,  0.0625, -0.0189,  ...,  0.0291,  0.0030, -0.0018],\n",
       "           [ 0.0370, -0.0659, -0.0216,  ..., -0.2603,  0.0560,  0.0378],\n",
       "           ...,\n",
       "           [-0.0347,  0.1300,  0.1235,  ...,  0.6518, -0.0167, -0.1235],\n",
       "           [-0.0196,  0.1224, -0.2488,  ...,  0.3304, -0.3203,  0.0944],\n",
       "           [ 0.0021,  0.0252, -0.0830,  ..., -0.0690,  0.0204, -0.0154]],\n",
       " \n",
       "          [[ 0.0131, -0.0371,  0.0200,  ..., -0.0464,  0.0261,  0.0026],\n",
       "           [-0.0333,  0.0753, -0.0288,  ...,  0.0475, -0.0072, -0.0160],\n",
       "           [ 0.0612, -0.0449, -0.1365,  ..., -0.1301,  0.0064,  0.0138],\n",
       "           ...,\n",
       "           [-0.0157,  0.0081,  0.1457,  ...,  0.4646, -0.1676, -0.0285],\n",
       "           [-0.0453,  0.0373, -0.1254,  ...,  0.1056, -0.2772,  0.1669],\n",
       "           [ 0.0105,  0.0190, -0.0154,  ..., -0.1135,  0.0676, -0.0068]]]],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    break\n",
    "    \n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_STATS = ([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n",
    "\n",
    "def open_image(image_name, colors, size):\n",
    "    image_name = str(image_name)\n",
    "    img = [io.imread(image_name+'_'+color+'.png').astype(np.float32)/255 for color in colors]    \n",
    "    if size is not None:\n",
    "        img = [transform.resize(c, (size, size), mode='reflect', anti_aliasing=False) for c in img]\n",
    "    img = np.stack(img, axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('/home/xmiler/projects/human-protein-atlas-image-classification/input/')\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, csv_file, images_dir,\n",
    "                 colors=['red', 'green', 'blue'], size=None, transforms=None):\n",
    "        csv_content = pd.read_csv(csv_file)\n",
    "        self._filenames = csv_content['Id'].tolist()        \n",
    "        self._labels = MultiLabelBinarizer().fit_transform([tuple(int(i) for i in item.split(' ')) for item in  csv_content['Target'].tolist()])\n",
    "        assert len(self._filenames) == len(self._labels)\n",
    "        self._images_dir = images_dir\n",
    "        self._colors = colors\n",
    "        self._size = size\n",
    "        self._transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = open_image(self._images_dir / self._filenames[idx], \n",
    "                           self._colors, self._size)\n",
    "        if self._transforms is not None:\n",
    "            image = self._transforms(image)\n",
    "        \n",
    "        labels = self._labels[idx]\n",
    "        \n",
    "        sample = {'image': image, 'labels': labels}        \n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(*IMG_STATS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinDataset(root_dir / 'train.csv', root_dir / 'train', size=224, transforms=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0396, dtype=torch.float64)\n",
      "tensor(0.8022, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "i = 103\n",
    "print(dataset[i]['image'][0].mean())\n",
    "print(dataset[i]['image'][0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=16, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i, batch in enumerate(dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
